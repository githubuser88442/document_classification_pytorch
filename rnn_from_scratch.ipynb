{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:07:39.143437Z",
     "start_time": "2018-07-30T20:07:24.918273Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:07:39.148441Z",
     "start_time": "2018-07-30T20:07:39.144939Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('DATA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset properties, inspection, tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:07:39.611771Z",
     "start_time": "2018-07-30T20:07:39.149942Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'x_and_y_cleaned.pkl'\n",
    "with open(DATA_PATH/DATASET_NAME, 'rb') as f:\n",
    "    articles, categories = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:08:13.967679Z",
     "start_time": "2018-07-30T20:08:13.962675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label None as 'none'\n",
    "categories = ['none' if not x else x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:08:14.215953Z",
     "start_time": "2018-07-30T20:08:14.202934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48514\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "CLASSES = sorted(list(set(categories)))\n",
    "ARTICLE_COUNT = len(articles)\n",
    "CLASS_COUNT = len(CLASSES)\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "MAX_SIZE = 250\n",
    "\n",
    "print(ARTICLE_COUNT)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T14:54:37.430701Z",
     "start_time": "2018-07-30T14:54:37.425697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiaeri', 'arvamus', 'arvamus/intervjuu', 'arvamus/juhtkiri', 'arvamus/karikatuur', 'arvamus/kommentaar', 'arvamus/koomiks', 'arvamus/lugejakiri', 'arvamus/nadalatipud', 'arvamus/repliik', 'arvamus/seisukoht', 'blogid/avastaeestimaad', 'blogid/aveameerikas', 'blogid/filmiblogi', 'blogid/hollandiblogi', 'blogid/indoneesiablogi', 'blogid/jumestusblogi', 'blogid/korvpallimm', 'blogid/lehesaba', 'blogid/londonilustiblogi', 'blogid/malluka', 'blogid/meistriteblogi', 'blogid/moeajakiri', 'blogid/moekeeris', 'blogid/motteid', 'blogid/muusikablogi', 'blogid/opetajablogi', 'blogid/psyhholoogiablogi', 'blogid/pulmablogi', 'blogid/raamatublogi', 'blogid/raha', 'blogid/seljakotigablogi', 'blogid/spordiblogi', 'blogid/teleblogi', 'blogid/trenniblogi', 'blogid/valdojahilo', 'blogid/yksikvanem', 'eestinaine/elud-inimesed', 'eriline/horoskoop', 'eriline/mystika', 'joulud', 'kroonika/eesti', 'lemmikloom', 'linnaleht/arvamus', 'linnaleht/dilaila', 'linnaleht/karikatuur', 'linnaleht/kodusedlood', 'linnaleht/paevateema', 'linnaleht/parnu', 'linnaleht/persoon', 'linnaleht/sport', 'linnaleht/tallinn', 'linnaleht/tarbija', 'linnaleht/tartu', 'linnaleht/toimetajaveerg', 'linnaleht/vabaaeg', 'meedia', 'meedia/galeriid', 'meedia/videod', 'mees/auto', 'mehele/reis', 'mehele/tehnika', 'melu/eestitop', 'melu/elu', 'melu/eurovision', 'melu/film', 'melu/saund', 'melu/saund/noorteband', 'melu/saund/noorteband/galeriid', 'melu/saund/noorteband/osalejad', 'melu/seltskond', 'melu/sunagukolab', 'naile/ilu', 'naine', 'naine/ilu', 'naine/naised', 'naine/stella', 'naine/suhted', 'naine/toit', 'none', 'oltv/ilukool', 'oltv/sporttv', 'oltv/uudistv', 'pokker', 'raha', 'raha/kodu', 'raha/rahakott', 'raha/tarbija', 'raha/tehnika', 'sport', 'sport/automoto', 'sport/doping', 'sport/hoki', 'sport/jalgpall', 'sport/jalgrattasport', 'sport/kasipall', 'sport/kergejoustik', 'sport/korvpall', 'sport/korvpallimm', 'sport/maadlus', 'sport/meistriteliiga', 'sport/mm2014', 'sport/muu', 'sport/nba', 'sport/nfl', 'sport/olympia', 'sport/soudmine', 'sport/talisport', 'sport/tantsutydrukud', 'sport/tennis', 'sport/ujumine', 'sport/varia', 'sport/vehklemine', 'sport/vorkpall', 'sport/vormel', 'televeeb/tvuudised', 'tervis', 'tervis/eakad', 'tervis/heanou', 'tervis/hygieen', 'tervis/keha', 'tervis/kysimus', 'tervis/lapsed', 'tervis/meeled', 'tervis/raamat', 'tervis/rasedus', 'tervis/toitumine', 'tervis/treenimine', 'tervis/uudised', 'uudised', 'uudised/eesti', 'uudised/ilm', 'uudised/kiiksud', 'uudised/krimi', 'uudised/maailm', 'uudised/ol70', 'uudised/presidendiball', 'uudised/valimised']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:19:48.069841Z",
     "start_time": "2018-07-29T21:19:48.058332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:  Kas parima aastavahetuse programmi pani eetrisse ETV, Kanal 2 või hoopis TV3? ETVst näegid vaatajad saateid \"V ...\n",
      "CATEGORY:  televeeb/tvuudised\n"
     ]
    }
   ],
   "source": [
    "# Dataset examples:\n",
    "index = 0\n",
    "print('ARTICLE: ', articles[index][0:110], '...')\n",
    "print('CATEGORY: ', categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:18:44.131826Z",
     "start_time": "2018-07-29T21:18:41.169277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.0\n",
      "387.0457805994146\n"
     ]
    }
   ],
   "source": [
    "# Get median/average word count\n",
    "print(np.median([len(x.split(' ')) for x in articles]))\n",
    "print(np.mean([len(x.split(' ')) for x in articles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T15:03:40.671064Z",
     "start_time": "2018-07-30T15:03:40.227644Z"
    }
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# labels = []\n",
    "# for x in categories:\n",
    "#     y = [0 for x in range(CLASS_COUNT)]\n",
    "#     y[CLASSES.index(x)] = 1\n",
    "#     labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T15:04:41.121571Z",
     "start_time": "2018-07-30T15:04:39.866224Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(articles, labels, test_size=0.1, random_state=42)\n",
    "pickle.dump([train_texts, val_texts, train_labels, val_labels], open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_split.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:08:22.765914Z",
     "start_time": "2018-07-30T20:08:22.763422Z"
    }
   },
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:01.369147Z",
     "start_time": "2018-07-30T13:19:35.308770Z"
    }
   },
   "outputs": [],
   "source": [
    "tok_train = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(train_texts))\n",
    "tok_val = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:18.105637Z",
     "start_time": "2018-07-30T13:25:14.806690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 657926),\n",
       " ('.', 559252),\n",
       " ('\"', 217175),\n",
       " ('ja', 210514),\n",
       " ('on', 197759),\n",
       " ('et', 150766),\n",
       " ('ei', 106727),\n",
       " ('kui', 74991),\n",
       " ('ta', 66639),\n",
       " ('ka', 58212),\n",
       " ('oli', 51101),\n",
       " ('oma', 46727),\n",
       " ('-', 46020),\n",
       " ('ning', 45314),\n",
       " ('see', 45285),\n",
       " ('xbos', 43662),\n",
       " ('xfld', 43662),\n",
       " ('0', 42597),\n",
       " ('aga', 38936),\n",
       " ('t_up', 31812),\n",
       " ('mis', 31436),\n",
       " ('ma', 30478),\n",
       " ('siis', 29830),\n",
       " ('kes', 29218),\n",
       " ('tema', 28739)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_train for p in o)\n",
    "print(len(tok_train))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:32.945314Z",
     "start_time": "2018-07-30T13:25:32.940310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xbos', 'vehklemisliidu', 'president', ',', 'riigikogu', 'liige', 'margus', 'hanson', 'tõdes', ',', 'et', 'naiskond', 'vehkles', 'kaunilt', 'kuni', 'finaalini', '.', '\"', 'naised', 'olid', 'väga', 'tublid', '.', 'meil', 'on', 'noor', ',', 'perspektiivikas', 'ja', 'arenev', 'võistkond', ':', 'teise', 'kohaga', 'tuleb', 'igati', 'rahul', 'olla', ',', 'sest', 'ega', 'jõu', 'ja', 'võimu', 'vastu', 'ei', 'saa', '!', '\"', 'hanson', 'lisas', ',', 'et', 'teda', 'rõõmustab', 'sten', 'priinitsa', 'individuaalturniiril', 'saadud', 'kaheksas', 'koht', ',', 'millega', 'mees', 'suurendab', 'ka', 't_up', 'eok', 'toetusraha', '.', '\"', 'meie', 'vehklejad', 'on', 'tõestanud', ',', 'et', 'neid', 'saab', 'usaldada', '.', 'sportlased', 'seavad', 'kõrged', 'sihid', 'ja', 'on', 'võimelised', 'neid', 'täitma', ';', '\"', 'kinnitas', 'ta', '.', 'ühtlasi', 'märkis', 'hanson', ',', 'et', 'suur', 'on', 'treener', 'igor', 'tšikinjovi', 'panus', '.', '\"', 'ta', 'on', 'toonud', 'värsket', 'verd', 'ja', 'hingamist', '.', 'see', 'on', 'hästi', 'mõjunud', '.', '\"', 'xfld', 'tk_wrep', '151', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:48.253589Z",
     "start_time": "2018-07-30T13:25:47.768744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 72534),\n",
       " ('.', 62293),\n",
       " ('\"', 23741),\n",
       " ('ja', 23599),\n",
       " ('on', 21847),\n",
       " ('et', 16600),\n",
       " ('ei', 11625),\n",
       " ('kui', 8402),\n",
       " ('ta', 7294),\n",
       " ('ka', 6594),\n",
       " ('oli', 5541),\n",
       " ('ning', 5219),\n",
       " ('oma', 5142),\n",
       " ('-', 5101),\n",
       " ('see', 4893),\n",
       " ('xbos', 4852),\n",
       " ('xfld', 4852),\n",
       " ('0', 4743),\n",
       " ('aga', 4345),\n",
       " ('mis', 3589),\n",
       " ('t_up', 3475),\n",
       " ('ma', 3323),\n",
       " ('tema', 3264),\n",
       " ('eesti', 3248),\n",
       " ('siis', 3235)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_val = Counter(p for o in tok_val for p in o)\n",
    "print(len(tok_val))\n",
    "freq_val.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:09.459592Z",
     "start_time": "2018-07-30T13:26:04.771503Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens/tok_train_pad.npy', tok_train)\n",
    "np.save(DATA_PATH/'tokens/tok_val_pad.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:24.815144Z",
     "start_time": "2018-07-30T13:26:24.558458Z"
    }
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:40.051470Z",
     "start_time": "2018-07-30T13:26:40.007939Z"
    }
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:43:10.741270Z",
     "start_time": "2018-07-30T13:43:06.742874Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lm = np.array([[stoi[o] for o in p] for p in tok_train])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:01.204885Z",
     "start_time": "2018-07-30T13:52:00.857137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pad and crop values\n",
    "train_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in train_lm]\n",
    "val_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in val_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:28.419054Z",
     "start_time": "2018-07-30T13:52:27.621530Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens'/'trn_ids.npy', train_lm_pad) # Oversaved all as padded\n",
    "np.save(DATA_PATH/'tokens'/'val_ids.npy', val_lm_pad)\n",
    "pickle.dump(itos, open(DATA_PATH/'tokens'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:08:29.004400Z",
     "start_time": "2018-07-30T20:08:28.266875Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = pickle.load(open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_split.pkl', 'rb'))\n",
    "train_lm = np.load(DATA_PATH/'tokens'/'trn_ids.npy')\n",
    "val_lm = np.load(DATA_PATH/'tokens'/'val_ids.npy')\n",
    "itos = pickle.load(open(DATA_PATH/'tokens'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:41:06.002194Z",
     "start_time": "2018-07-30T13:41:05.996690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos Peaminister Taavi Rõivas jätab võimutüli tõttu ära visiidid Leedusse ja Rootsi, teda asendab väliskaubandus- ja ettevõtlusminister Anne Sulling.  Valitsuse pressiesindaja kinnitas pühapäeva pärastlõunal, et Rõivas ei sõida esmaspäeval visiidile Leetu ja Rootsi. Pressiesindaja teatel jäävad visiidid ära \"seoses ametikohustustega Eestis\". Reformierakonna esimees, peaminister Taavi Rõivas pidi esmaspäeval koos teiste Balti riikide valitsusjuhtidega osalema Leedus Klaipedas aset leidval LNG ujuvterminali saabumistseremoonial. Enne tseremooniat pidi aset leidma peaministrite ning Ameerika Ühendriikide esindajate ühine töölõuna. Pärastlõunal pidi Rõivas suunduma edasi Stockholmi, kus toimub Balti- ja Põhjamaade tippkohtumine. Rootsi, Soome, Norra, Islandi, Taani, Eesti, Läti ja Leedu peaministrite kohtumisel räägitakse majanduse olukorrast Euroopas, transatlantilistest suhetest ning Ukrainaga seotud arengutest. Pühapäeval kohtuvad Reformierakonna ja Sotsiaaldemokraatliku Erakonna esimehed, et arutada rahandusminister Jürgen Ligi väljaütlemisest puhkenud tüli. xfld 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:46:21.018841Z",
     "start_time": "2018-07-30T13:46:21.015339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 425, 524, 658, 2109, 0, 254, 63, 48013, 0, 5, 563, 2, 84, 28902, 0, 5, 53171, 1428, 26646, 3, 64, 755, 588, 438, 2029, 1368, 2, 7, 658, 8, 7061, 661, 4845, 17602, 5, 563, 3, 588, 704, 1070, 48013, 63, 4, 552, 0, 136, 4, 3, 813, 829, 2, 425, 524, 658, 388, 661, 79, 383, 555, 1197, 0, 3403, 5258, 0, 1815, 0, 21, 11591, 0, 0, 3, 105, 50278, 388, 1815, 3905, 31416, 15, 542, 1406, 7017, 3196, 0, 3, 1368, 388, 658, 0, 180, 3805, 2, 45, 638, 50279, 5, 9650, 11347, 3, 563, 2, 322, 2, 954, 2, 5409, 2, 2147, 2, 27, 2, 662, 5, 1109, 31416, 2357, 2275, 3893, 3806, 938, 2, 0, 5920, 15, 12824, 433, 43618, 3, 679, 10646, 813, 5, 7930, 871, 48014, 2, 7, 3819, 1726, 1064, 194, 0, 7214, 1899, 3, 18, 37, 7215, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T15:05:52.605096Z",
     "start_time": "2018-07-30T15:05:52.599591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "uudised/eesti\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(CLASSES[train_labels[0].index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:46:21.949773Z",
     "start_time": "2018-07-30T20:46:21.542483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([43662, 250])\n",
      "y shape torch.Size([43662, 138])\n"
     ]
    }
   ],
   "source": [
    "bs=32\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(train_lm, np.asarray(train_labels))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:46:22.728385Z",
     "start_time": "2018-07-30T20:46:22.710383Z"
    }
   },
   "outputs": [],
   "source": [
    "test_values = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:46:23.066656Z",
     "start_time": "2018-07-30T20:46:23.062160Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = next(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:46:23.306389Z",
     "start_time": "2018-07-30T20:46:23.301885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   17,     0, 21504,  ...,   479,     0,     0],\n",
      "        [   17,  2174,   324,  ...,    36,     0,     0],\n",
      "        [   17,  8247,  8102,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   17,     0,     0,  ...,     0,     0,     0],\n",
      "        [   17,  4644,  2135,  ...,     0,     0,     0],\n",
      "        [   17,  3012,     0,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T20:46:23.769247Z",
     "start_time": "2018-07-30T20:46:23.765745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:18:20.477998Z",
     "start_time": "2018-07-30T21:18:20.472494Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, num_l, neurons: List[int], e_size=200):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.input_l = nn.Linear(e_size * input_size, neurons[0])\n",
    "        self.middle_l = nn.ModuleList()\n",
    "        for i in range(num_l):\n",
    "            self.middle_l.append(nn.Linear(neurons[i], neurons[i+1]))\n",
    "        self.output_l = nn.Linear(neurons[-1], num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        i_sz = x.shape[-1]\n",
    "        x = F.relu(self.e(x))\n",
    "        x = x.view(-1,  i_sz * x.shape[-1])\n",
    "        x = F.relu(self.input_l(x))\n",
    "        for l in self.middle_l:\n",
    "            x = F.relu(l(x))\n",
    "        return F.softmax(self.output_l(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:18:20.926039Z",
     "start_time": "2018-07-30T21:18:20.673329Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFNN(\n",
      "  (e): Embedding(60000, 200)\n",
      "  (input_l): Linear(in_features=50000, out_features=200, bias=True)\n",
      "  (middle_l): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  )\n",
      "  (output_l): Linear(in_features=20, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = SimpleFNN(MAX_SIZE, max_vocab, CLASS_COUNT, 4, [200, 300, 100, 50, 20]).cuda()\n",
    "print(fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:18:24.289107Z",
     "start_time": "2018-07-30T21:18:24.281101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pass through\n",
    "fnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:23:52.684939Z",
     "start_time": "2018-07-30T21:23:52.681938Z"
    }
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(fnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:27:10.061632Z",
     "start_time": "2018-07-30T21:24:01.954734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]> <ipython-input-118-8b5fc0479f52>(8)<module>()\n",
      "-> y_h = fnn(x)\n",
      "(Pdb) y_h\n",
      "tensor([[0.0073, 0.0063, 0.0063,  ..., 0.0080, 0.0063, 0.0085],\n",
      "        [0.0073, 0.0063, 0.0063,  ..., 0.0081, 0.0063, 0.0085],\n",
      "        [0.0073, 0.0063, 0.0063,  ..., 0.0080, 0.0063, 0.0085],\n",
      "        ...,\n",
      "        [0.0073, 0.0063, 0.0063,  ..., 0.0080, 0.0063, 0.0085],\n",
      "        [0.0073, 0.0063, 0.0063,  ..., 0.0080, 0.0063, 0.0085],\n",
      "        [0.0073, 0.0063, 0.0063,  ..., 0.0081, 0.0063, 0.0085]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "(Pdb) y\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
      "(Pdb) y_h.shape\n",
      "torch.Size([32, 138])\n",
      "(Pdb) y.shape\n",
      "torch.Size([32, 138])\n",
      "(Pdb) sum(y_h[0]\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "(Pdb) sum(y_h[0])\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<ThAddBackward>)\n",
      "(Pdb) cirt\n",
      "*** NameError: name 'cirt' is not defined\n",
      "(Pdb) crit\n",
      "CrossEntropyLoss()\n",
      "(Pdb) crit(y_h, y)\n",
      "*** RuntimeError: multi-target not supported at c:\\new-builder_2\\win-wheel\\pytorch\\aten\\src\\thcunn\\generic/ClassNLLCriterion.cu:15\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-8b5fc0479f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0my_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m250\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-8b5fc0479f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0my_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m250\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(5):\n",
    "    for i, data in tqdm(enumerate(dl, 0)):\n",
    "        x, y = data\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        import pdb;pdb.set_trace()\n",
    "        y_h = fnn(x)\n",
    "        loss = crit(y_h, y)\n",
    "        if i % 250 == 0:\n",
    "            print(f'Epoch: {ep} | loss {loss.item()}')\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "43px",
    "left": "1548px",
    "right": "20px",
    "top": "118px",
    "width": "302px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
