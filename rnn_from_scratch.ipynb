{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:28:50.858128Z",
     "start_time": "2018-08-03T22:28:35.606955Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:28:50.864151Z",
     "start_time": "2018-08-03T22:28:50.860147Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('DATA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset properties, inspection, tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:28:52.258742Z",
     "start_time": "2018-08-03T22:28:50.865134Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'x_and_y_cleaned.pkl'\n",
    "with open(DATA_PATH/DATASET_NAME, 'rb') as f:\n",
    "    articles, categories = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:28:52.275763Z",
     "start_time": "2018-08-03T22:28:52.263742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label None as 'none'\n",
    "categories = ['none' if not x else x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:28:52.372923Z",
     "start_time": "2018-08-03T22:28:52.278754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48514\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "CLASSES = sorted(list(set(categories)))\n",
    "ARTICLE_COUNT = len(articles)\n",
    "CLASS_COUNT = len(CLASSES)\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "MAX_SIZE = 250\n",
    "\n",
    "max_vocab = 60000\n",
    "min_freq = 5\n",
    "\n",
    "print(ARTICLE_COUNT)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:25:15.634508Z",
     "start_time": "2018-08-02T20:25:15.622498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uudised/eesti', 16451),\n",
       " ('melu/elu', 5883),\n",
       " ('uudised/maailm', 4285),\n",
       " ('uudised/krimi', 2211),\n",
       " ('televeeb/tvuudised', 1462),\n",
       " ('arvamus/kommentaar', 1342),\n",
       " ('naine/naised', 1163),\n",
       " ('naine/suhted', 1155),\n",
       " ('melu/seltskond', 969),\n",
       " ('sport/jalgpall', 885),\n",
       " ('naine/ilu', 817),\n",
       " ('uudised/kiiksud', 544),\n",
       " ('sport/korvpall', 541),\n",
       " ('tervis/keha', 502),\n",
       " ('blogid/londonilustiblogi', 480),\n",
       " ('uudised/ilm', 461),\n",
       " ('arvamus/juhtkiri', 454),\n",
       " ('sport/varia', 413),\n",
       " ('raha/kodu', 353),\n",
       " ('meedia/galeriid', 334),\n",
       " ('arvamus/repliik', 324),\n",
       " ('melu/saund', 323),\n",
       " ('melu/sunagukolab', 322),\n",
       " ('sport/kergejoustik', 316),\n",
       " ('meedia/videod', 315)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class balance check:\n",
    "freq = Counter(o for o in categories)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:45:56.198864Z",
     "start_time": "2018-08-01T18:45:56.192361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiaeri', 'arvamus', 'arvamus/intervjuu', 'arvamus/juhtkiri', 'arvamus/karikatuur', 'arvamus/kommentaar', 'arvamus/koomiks', 'arvamus/lugejakiri', 'arvamus/nadalatipud', 'arvamus/repliik', 'arvamus/seisukoht', 'blogid/avastaeestimaad', 'blogid/aveameerikas', 'blogid/filmiblogi', 'blogid/hollandiblogi', 'blogid/indoneesiablogi', 'blogid/jumestusblogi', 'blogid/korvpallimm', 'blogid/lehesaba', 'blogid/londonilustiblogi', 'blogid/malluka', 'blogid/meistriteblogi', 'blogid/moeajakiri', 'blogid/moekeeris', 'blogid/motteid', 'blogid/muusikablogi', 'blogid/opetajablogi', 'blogid/psyhholoogiablogi', 'blogid/pulmablogi', 'blogid/raamatublogi', 'blogid/raha', 'blogid/seljakotigablogi', 'blogid/spordiblogi', 'blogid/teleblogi', 'blogid/trenniblogi', 'blogid/valdojahilo', 'blogid/yksikvanem', 'eestinaine/elud-inimesed', 'eriline/horoskoop', 'eriline/mystika', 'joulud', 'kroonika/eesti', 'lemmikloom', 'linnaleht/arvamus', 'linnaleht/dilaila', 'linnaleht/karikatuur', 'linnaleht/kodusedlood', 'linnaleht/paevateema', 'linnaleht/parnu', 'linnaleht/persoon', 'linnaleht/sport', 'linnaleht/tallinn', 'linnaleht/tarbija', 'linnaleht/tartu', 'linnaleht/toimetajaveerg', 'linnaleht/vabaaeg', 'meedia', 'meedia/galeriid', 'meedia/videod', 'mees/auto', 'mehele/reis', 'mehele/tehnika', 'melu/eestitop', 'melu/elu', 'melu/eurovision', 'melu/film', 'melu/saund', 'melu/saund/noorteband', 'melu/saund/noorteband/galeriid', 'melu/saund/noorteband/osalejad', 'melu/seltskond', 'melu/sunagukolab', 'naile/ilu', 'naine', 'naine/ilu', 'naine/naised', 'naine/stella', 'naine/suhted', 'naine/toit', 'none', 'oltv/ilukool', 'oltv/sporttv', 'oltv/uudistv', 'pokker', 'raha', 'raha/kodu', 'raha/rahakott', 'raha/tarbija', 'raha/tehnika', 'sport', 'sport/automoto', 'sport/doping', 'sport/hoki', 'sport/jalgpall', 'sport/jalgrattasport', 'sport/kasipall', 'sport/kergejoustik', 'sport/korvpall', 'sport/korvpallimm', 'sport/maadlus', 'sport/meistriteliiga', 'sport/mm2014', 'sport/muu', 'sport/nba', 'sport/nfl', 'sport/olympia', 'sport/soudmine', 'sport/talisport', 'sport/tantsutydrukud', 'sport/tennis', 'sport/ujumine', 'sport/varia', 'sport/vehklemine', 'sport/vorkpall', 'sport/vormel', 'televeeb/tvuudised', 'tervis', 'tervis/eakad', 'tervis/heanou', 'tervis/hygieen', 'tervis/keha', 'tervis/kysimus', 'tervis/lapsed', 'tervis/meeled', 'tervis/raamat', 'tervis/rasedus', 'tervis/toitumine', 'tervis/treenimine', 'tervis/uudised', 'uudised', 'uudised/eesti', 'uudised/ilm', 'uudised/kiiksud', 'uudised/krimi', 'uudised/maailm', 'uudised/ol70', 'uudised/presidendiball', 'uudised/valimised']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:19:48.069841Z",
     "start_time": "2018-07-29T21:19:48.058332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:  Kas parima aastavahetuse programmi pani eetrisse ETV, Kanal 2 või hoopis TV3? ETVst näegid vaatajad saateid \"V ...\n",
      "CATEGORY:  televeeb/tvuudised\n"
     ]
    }
   ],
   "source": [
    "# Dataset examples:\n",
    "index = 0\n",
    "print('ARTICLE: ', articles[index][0:110], '...')\n",
    "print('CATEGORY: ', categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:18:44.131826Z",
     "start_time": "2018-07-29T21:18:41.169277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.0\n",
      "387.0457805994146\n"
     ]
    }
   ],
   "source": [
    "# Get median/average word count\n",
    "print(np.median([len(x.split(' ')) for x in articles]))\n",
    "print(np.mean([len(x.split(' ')) for x in articles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:33.989982Z",
     "start_time": "2018-07-31T12:20:33.893399Z"
    }
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# labels = []\n",
    "# for x in categories:\n",
    "#     y = [0 for x in range(CLASS_COUNT)]\n",
    "#     y[CLASSES.index(x)] = 1\n",
    "#     labels.append(y)\n",
    "\n",
    "# Class index encoding\n",
    "labels = []\n",
    "for x in categories:\n",
    "    y = CLASSES.index(x)\n",
    "    labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:55.175534Z",
     "start_time": "2018-07-31T12:20:54.333043Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(articles, labels, test_size=0.1, random_state=42)\n",
    "pickle.dump([train_texts, val_texts, train_labels, val_labels], open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:01.369147Z",
     "start_time": "2018-07-30T13:19:35.308770Z"
    }
   },
   "outputs": [],
   "source": [
    "tok_train = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(train_texts))\n",
    "tok_val = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:18.105637Z",
     "start_time": "2018-07-30T13:25:14.806690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 657926),\n",
       " ('.', 559252),\n",
       " ('\"', 217175),\n",
       " ('ja', 210514),\n",
       " ('on', 197759),\n",
       " ('et', 150766),\n",
       " ('ei', 106727),\n",
       " ('kui', 74991),\n",
       " ('ta', 66639),\n",
       " ('ka', 58212),\n",
       " ('oli', 51101),\n",
       " ('oma', 46727),\n",
       " ('-', 46020),\n",
       " ('ning', 45314),\n",
       " ('see', 45285),\n",
       " ('xbos', 43662),\n",
       " ('xfld', 43662),\n",
       " ('0', 42597),\n",
       " ('aga', 38936),\n",
       " ('t_up', 31812),\n",
       " ('mis', 31436),\n",
       " ('ma', 30478),\n",
       " ('siis', 29830),\n",
       " ('kes', 29218),\n",
       " ('tema', 28739)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_train for p in o)\n",
    "print(len(tok_train))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:32.945314Z",
     "start_time": "2018-07-30T13:25:32.940310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xbos', 'vehklemisliidu', 'president', ',', 'riigikogu', 'liige', 'margus', 'hanson', 'tõdes', ',', 'et', 'naiskond', 'vehkles', 'kaunilt', 'kuni', 'finaalini', '.', '\"', 'naised', 'olid', 'väga', 'tublid', '.', 'meil', 'on', 'noor', ',', 'perspektiivikas', 'ja', 'arenev', 'võistkond', ':', 'teise', 'kohaga', 'tuleb', 'igati', 'rahul', 'olla', ',', 'sest', 'ega', 'jõu', 'ja', 'võimu', 'vastu', 'ei', 'saa', '!', '\"', 'hanson', 'lisas', ',', 'et', 'teda', 'rõõmustab', 'sten', 'priinitsa', 'individuaalturniiril', 'saadud', 'kaheksas', 'koht', ',', 'millega', 'mees', 'suurendab', 'ka', 't_up', 'eok', 'toetusraha', '.', '\"', 'meie', 'vehklejad', 'on', 'tõestanud', ',', 'et', 'neid', 'saab', 'usaldada', '.', 'sportlased', 'seavad', 'kõrged', 'sihid', 'ja', 'on', 'võimelised', 'neid', 'täitma', ';', '\"', 'kinnitas', 'ta', '.', 'ühtlasi', 'märkis', 'hanson', ',', 'et', 'suur', 'on', 'treener', 'igor', 'tšikinjovi', 'panus', '.', '\"', 'ta', 'on', 'toonud', 'värsket', 'verd', 'ja', 'hingamist', '.', 'see', 'on', 'hästi', 'mõjunud', '.', '\"', 'xfld', 'tk_wrep', '151', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:48.253589Z",
     "start_time": "2018-07-30T13:25:47.768744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 72534),\n",
       " ('.', 62293),\n",
       " ('\"', 23741),\n",
       " ('ja', 23599),\n",
       " ('on', 21847),\n",
       " ('et', 16600),\n",
       " ('ei', 11625),\n",
       " ('kui', 8402),\n",
       " ('ta', 7294),\n",
       " ('ka', 6594),\n",
       " ('oli', 5541),\n",
       " ('ning', 5219),\n",
       " ('oma', 5142),\n",
       " ('-', 5101),\n",
       " ('see', 4893),\n",
       " ('xbos', 4852),\n",
       " ('xfld', 4852),\n",
       " ('0', 4743),\n",
       " ('aga', 4345),\n",
       " ('mis', 3589),\n",
       " ('t_up', 3475),\n",
       " ('ma', 3323),\n",
       " ('tema', 3264),\n",
       " ('eesti', 3248),\n",
       " ('siis', 3235)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_val = Counter(p for o in tok_val for p in o)\n",
    "print(len(tok_val))\n",
    "freq_val.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:09.459592Z",
     "start_time": "2018-07-30T13:26:04.771503Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens/tok_train_pad.npy', tok_train)\n",
    "np.save(DATA_PATH/'tokens/tok_val_pad.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:24.815144Z",
     "start_time": "2018-07-30T13:26:24.558458Z"
    }
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:40.051470Z",
     "start_time": "2018-07-30T13:26:40.007939Z"
    }
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:43:10.741270Z",
     "start_time": "2018-07-30T13:43:06.742874Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lm = np.array([[stoi[o] for o in p] for p in tok_train])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:01.204885Z",
     "start_time": "2018-07-30T13:52:00.857137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pad and crop values\n",
    "train_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in train_lm]\n",
    "val_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in val_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:28.419054Z",
     "start_time": "2018-07-30T13:52:27.621530Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens'/'trn_ids.npy', train_lm_pad) # Oversaved all as padded\n",
    "np.save(DATA_PATH/'tokens'/'val_ids.npy', val_lm_pad)\n",
    "pickle.dump(itos, open(DATA_PATH/'tokens'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:29:20.722139Z",
     "start_time": "2018-08-03T22:29:20.123158Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = pickle.load(open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'rb'))\n",
    "train_lm = np.load(DATA_PATH/'tokens'/'trn_ids.npy')\n",
    "val_lm = np.load(DATA_PATH/'tokens'/'val_ids.npy')\n",
    "itos = pickle.load(open(DATA_PATH/'tokens'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:41:06.002194Z",
     "start_time": "2018-07-30T13:41:05.996690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos Peaminister Taavi Rõivas jätab võimutüli tõttu ära visiidid Leedusse ja Rootsi, teda asendab väliskaubandus- ja ettevõtlusminister Anne Sulling.  Valitsuse pressiesindaja kinnitas pühapäeva pärastlõunal, et Rõivas ei sõida esmaspäeval visiidile Leetu ja Rootsi. Pressiesindaja teatel jäävad visiidid ära \"seoses ametikohustustega Eestis\". Reformierakonna esimees, peaminister Taavi Rõivas pidi esmaspäeval koos teiste Balti riikide valitsusjuhtidega osalema Leedus Klaipedas aset leidval LNG ujuvterminali saabumistseremoonial. Enne tseremooniat pidi aset leidma peaministrite ning Ameerika Ühendriikide esindajate ühine töölõuna. Pärastlõunal pidi Rõivas suunduma edasi Stockholmi, kus toimub Balti- ja Põhjamaade tippkohtumine. Rootsi, Soome, Norra, Islandi, Taani, Eesti, Läti ja Leedu peaministrite kohtumisel räägitakse majanduse olukorrast Euroopas, transatlantilistest suhetest ning Ukrainaga seotud arengutest. Pühapäeval kohtuvad Reformierakonna ja Sotsiaaldemokraatliku Erakonna esimehed, et arutada rahandusminister Jürgen Ligi väljaütlemisest puhkenud tüli. xfld 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:46:21.018841Z",
     "start_time": "2018-07-30T13:46:21.015339Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 425, 524, 658, 2109, 0, 254, 63, 48013, 0, 5, 563, 2, 84, 28902, 0, 5, 53171, 1428, 26646, 3, 64, 755, 588, 438, 2029, 1368, 2, 7, 658, 8, 7061, 661, 4845, 17602, 5, 563, 3, 588, 704, 1070, 48013, 63, 4, 552, 0, 136, 4, 3, 813, 829, 2, 425, 524, 658, 388, 661, 79, 383, 555, 1197, 0, 3403, 5258, 0, 1815, 0, 21, 11591, 0, 0, 3, 105, 50278, 388, 1815, 3905, 31416, 15, 542, 1406, 7017, 3196, 0, 3, 1368, 388, 658, 0, 180, 3805, 2, 45, 638, 50279, 5, 9650, 11347, 3, 563, 2, 322, 2, 954, 2, 5409, 2, 2147, 2, 27, 2, 662, 5, 1109, 31416, 2357, 2275, 3893, 3806, 938, 2, 0, 5920, 15, 12824, 433, 43618, 3, 679, 10646, 813, 5, 7930, 871, 48014, 2, 7, 3819, 1726, 1064, 194, 0, 7214, 1899, 3, 18, 37, 7215, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:21:46.538046Z",
     "start_time": "2018-07-31T12:21:46.534044Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "uudised/eesti\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(CLASSES[train_labels[0]])\n",
    "# print(CLASSES[train_labels[0].index(1)]) # for one hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:25.573338Z",
     "start_time": "2018-08-03T22:40:25.510794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([43662, 250])\n",
      "y shape torch.Size([43662])\n",
      "x shape torch.Size([4852, 250])\n",
      "y shape torch.Size([4852])\n"
     ]
    }
   ],
   "source": [
    "bs=32\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(train_lm, np.asarray(train_labels))\n",
    "ds_val = TokDataset(val_lm, np.asarray(val_labels))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:25.682953Z",
     "start_time": "2018-08-03T22:40:25.678451Z"
    }
   },
   "outputs": [],
   "source": [
    "test_values = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:26.054875Z",
     "start_time": "2018-08-03T22:40:26.046359Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = next(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:26.486226Z",
     "start_time": "2018-08-03T22:40:26.479221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   17,  1086,    94,  ...,     3,     0,     0],\n",
      "        [   17,   972,  1452,  ...,     0,     0,     0],\n",
      "        [   17,     4,    27,  ...,    66,     0,     0],\n",
      "        ...,\n",
      "        [   17,   176,  4905,  ...,     0,     0,     0],\n",
      "        [   17,  5620, 13214,  ...,     0,     0,     0],\n",
      "        [   17,  4135,  1327,  ...,     3,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feed-forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:22:09.018109Z",
     "start_time": "2018-07-31T12:22:09.013614Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:21.938615Z",
     "start_time": "2018-07-31T15:45:21.929599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, num_l, neurons: List[int], e_size=200):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.input_l = nn.Linear(e_size * input_size, neurons[0])\n",
    "        self.middle_l = nn.ModuleList()\n",
    "        for i in range(num_l):\n",
    "            self.middle_l.append(nn.Linear(neurons[i], neurons[i+1]))\n",
    "        self.output_l = nn.Linear(neurons[-1], num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        i_sz = x.shape[-1]\n",
    "        x = F.relu(self.e(x))\n",
    "        x = x.view(-1,  i_sz * x.shape[-1])\n",
    "        x = F.relu(self.input_l(x))\n",
    "        for l in self.middle_l:\n",
    "            x = F.relu(l(x))\n",
    "        return self.output_l(x) # No softmax for crossentropy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:25.090219Z",
     "start_time": "2018-07-31T15:45:24.863507Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFNN(\n",
      "  (e): Embedding(60000, 200)\n",
      "  (input_l): Linear(in_features=50000, out_features=200, bias=True)\n",
      "  (middle_l): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  )\n",
      "  (output_l): Linear(in_features=20, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = SimpleFNN(MAX_SIZE, max_vocab, CLASS_COUNT, 4, [200, 300, 100, 50, 20]).cuda()\n",
    "print(fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:29.340912Z",
     "start_time": "2018-07-31T15:45:29.335418Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pass through\n",
    "fnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T14:01:47.590476Z",
     "start_time": "2018-08-01T14:01:47.574966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(fnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:43:07.910783Z",
     "start_time": "2018-08-03T22:43:07.904769Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, val_dl, crit, opt, verb=250):\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            x, y = data\n",
    "            x = x.cuda(); y = y.cuda()\n",
    "\n",
    "            y_h = model(x)\n",
    "            loss = crit(y_h, y)\n",
    "            \n",
    "            # For accuracy\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y.size(0)\n",
    "            correct += (torch.argmax(y_h, 1) == y).sum().item()\n",
    "\n",
    "            if i % verb == 0:\n",
    "                print(f' Epoch: {ep} | b_loss: {loss.item():.{4}f}, b_acc: {100 * correct / total}')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Validate\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        for i, data_val in enumerate(val_dl):\n",
    "            x_val, y_val = data_val\n",
    "            x_val = x_val.cuda(); y_val = y_val.cuda()\n",
    "            \n",
    "            # .eval() doesn't turn off gradient tracking\n",
    "            with torch.no_grad():\n",
    "                y_h_val = model(x_val)\n",
    "                val_correct += (torch.argmax(y_h_val, 1) == y_val).sum().item()\n",
    "        print(f'\\nEPOCH {ep} - Val acc: {100 * val_correct / len(val_dl.dataset)}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:39:51.493499Z",
     "start_time": "2018-08-03T22:39:51.486993Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/model.py\n",
    "# https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "# Draft implementation\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, e_size=128, k_num=100, k_sizes=[3, 4, 5]):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, k_num, (k, e_size)) for k in k_sizes])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output_l = nn.Linear(len(k_sizes)*k_num, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.e(x)  # (N, W, D)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] \n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        return self.output_l(x)\n",
    "\n",
    "    \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:39:51.881526Z",
     "start_time": "2018-08-03T22:39:51.783858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (e): Embedding(60000, 128)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 128), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 128), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 128), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (output_l): Linear(in_features=300, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = SimpleCNN(MAX_SIZE, max_vocab, CLASS_COUNT).cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:31.474167Z",
     "start_time": "2018-08-03T22:40:29.743672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T22:40:41.098068Z",
     "start_time": "2018-08-03T22:40:41.095555Z"
    }
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(cnn.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:08:32.229668Z",
     "start_time": "2018-08-03T23:49:37.518443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 0.2625, b_acc: 93.75\n",
      "250it [00:13, 18.24it/s] Epoch: 0 | b_loss: 0.0825, b_acc: 100.0\n",
      "500it [00:27, 18.28it/s] Epoch: 0 | b_loss: 0.0604, b_acc: 100.0\n",
      "750it [00:41, 18.26it/s] Epoch: 0 | b_loss: 0.0373, b_acc: 100.0\n",
      "1000it [00:54, 18.31it/s] Epoch: 0 | b_loss: 0.0728, b_acc: 100.0\n",
      "1250it [01:08, 18.32it/s] Epoch: 0 | b_loss: 0.0088, b_acc: 100.0\n",
      "1365it [01:14, 18.32it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 92.37427864798022\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 0.1524, b_acc: 96.875\n",
      "250it [00:13, 18.35it/s] Epoch: 1 | b_loss: 0.1772, b_acc: 93.75\n",
      "500it [00:27, 18.38it/s] Epoch: 1 | b_loss: 0.1994, b_acc: 96.875\n",
      "750it [00:40, 18.34it/s] Epoch: 1 | b_loss: 0.0513, b_acc: 100.0\n",
      "1000it [00:54, 18.21it/s] Epoch: 1 | b_loss: 0.0367, b_acc: 100.0\n",
      "1250it [01:08, 18.16it/s] Epoch: 1 | b_loss: 0.1017, b_acc: 100.0\n",
      "1365it [01:15, 18.19it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 92.37427864798022\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 0.1365, b_acc: 93.75\n",
      "250it [00:13, 18.34it/s] Epoch: 2 | b_loss: 0.2468, b_acc: 96.875\n",
      "500it [00:27, 18.36it/s] Epoch: 2 | b_loss: 0.0215, b_acc: 100.0\n",
      "750it [00:40, 18.31it/s] Epoch: 2 | b_loss: 0.0309, b_acc: 100.0\n",
      "1000it [00:54, 18.34it/s] Epoch: 2 | b_loss: 0.1087, b_acc: 100.0\n",
      "1250it [01:08, 18.33it/s] Epoch: 2 | b_loss: 0.1718, b_acc: 93.75\n",
      "1365it [01:14, 18.30it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 92.47732893652102\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 0.1365, b_acc: 96.875\n",
      "250it [00:13, 18.08it/s] Epoch: 3 | b_loss: 0.0692, b_acc: 96.875\n",
      "500it [00:27, 18.07it/s] Epoch: 3 | b_loss: 0.1323, b_acc: 96.875\n",
      "750it [00:41, 18.05it/s] Epoch: 3 | b_loss: 0.0967, b_acc: 96.875\n",
      "1000it [00:55, 18.11it/s] Epoch: 3 | b_loss: 0.0161, b_acc: 100.0\n",
      "1250it [01:08, 18.17it/s] Epoch: 3 | b_loss: 0.0932, b_acc: 96.875\n",
      "1365it [01:15, 18.20it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 92.35366859027205\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.0803, b_acc: 100.0\n",
      "250it [00:13, 18.36it/s] Epoch: 4 | b_loss: 0.2381, b_acc: 93.75\n",
      "500it [00:27, 18.33it/s] Epoch: 4 | b_loss: 0.0566, b_acc: 100.0\n",
      "750it [00:40, 18.34it/s] Epoch: 4 | b_loss: 0.2729, b_acc: 87.5\n",
      "1000it [00:54, 18.25it/s] Epoch: 4 | b_loss: 0.0206, b_acc: 100.0\n",
      "1250it [01:08, 18.21it/s] Epoch: 4 | b_loss: 0.1916, b_acc: 96.875\n",
      "1365it [01:14, 18.20it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 92.55976916735366\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.0218, b_acc: 100.0\n",
      "250it [00:13, 18.07it/s] Epoch: 5 | b_loss: 0.0478, b_acc: 100.0\n",
      "500it [00:27, 17.99it/s] Epoch: 5 | b_loss: 0.0935, b_acc: 100.0\n",
      "750it [00:41, 17.97it/s] Epoch: 5 | b_loss: 0.0333, b_acc: 100.0\n",
      "1000it [00:55, 18.03it/s] Epoch: 5 | b_loss: 0.0131, b_acc: 100.0\n",
      "1250it [01:09, 18.10it/s] Epoch: 5 | b_loss: 0.1693, b_acc: 96.875\n",
      "1365it [01:15, 18.13it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 92.51854905193734\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.3113, b_acc: 96.875\n",
      "250it [00:13, 18.31it/s] Epoch: 6 | b_loss: 0.0921, b_acc: 93.75\n",
      "500it [00:27, 18.21it/s] Epoch: 6 | b_loss: 0.0466, b_acc: 100.0\n",
      "750it [00:41, 18.20it/s] Epoch: 6 | b_loss: 0.1077, b_acc: 96.875\n",
      "1000it [00:54, 18.21it/s] Epoch: 6 | b_loss: 0.0736, b_acc: 100.0\n",
      "1250it [01:08, 18.22it/s] Epoch: 6 | b_loss: 0.1583, b_acc: 93.75\n",
      "1365it [01:14, 18.25it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 92.35366859027205\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.0937, b_acc: 96.875\n",
      "250it [00:13, 18.02it/s] Epoch: 7 | b_loss: 0.0596, b_acc: 100.0\n",
      "500it [00:27, 18.17it/s] Epoch: 7 | b_loss: 0.0476, b_acc: 100.0\n",
      "750it [00:41, 18.18it/s] Epoch: 7 | b_loss: 0.0836, b_acc: 100.0\n",
      "1000it [00:54, 18.22it/s] Epoch: 7 | b_loss: 0.0185, b_acc: 100.0\n",
      "1250it [01:08, 18.26it/s] Epoch: 7 | b_loss: 0.0086, b_acc: 100.0\n",
      "1365it [01:14, 18.29it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 92.4361088211047\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.0234, b_acc: 100.0\n",
      "250it [00:13, 18.41it/s] Epoch: 8 | b_loss: 0.0180, b_acc: 100.0\n",
      "500it [00:27, 18.24it/s] Epoch: 8 | b_loss: 0.0629, b_acc: 100.0\n",
      "750it [00:41, 18.23it/s] Epoch: 8 | b_loss: 0.0733, b_acc: 96.875\n",
      "1000it [00:54, 18.27it/s] Epoch: 8 | b_loss: 0.0274, b_acc: 100.0\n",
      "1250it [01:08, 18.29it/s] Epoch: 8 | b_loss: 0.0710, b_acc: 96.875\n",
      "1365it [01:14, 18.29it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 92.3330585325639\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.0211, b_acc: 100.0\n",
      "250it [00:13, 17.98it/s] Epoch: 9 | b_loss: 0.0318, b_acc: 100.0\n",
      "500it [00:27, 18.01it/s] Epoch: 9 | b_loss: 0.0389, b_acc: 100.0\n",
      "750it [00:41, 18.12it/s] Epoch: 9 | b_loss: 0.0450, b_acc: 96.875\n",
      "1000it [00:55, 18.18it/s] Epoch: 9 | b_loss: 0.0176, b_acc: 100.0\n",
      "1250it [01:08, 18.18it/s] Epoch: 9 | b_loss: 0.0478, b_acc: 100.0\n",
      "1365it [01:15, 18.19it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 92.3330585325639\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.0772, b_acc: 96.875\n",
      "250it [00:13, 18.12it/s] Epoch: 10 | b_loss: 0.0322, b_acc: 100.0\n",
      "500it [00:27, 18.08it/s] Epoch: 10 | b_loss: 0.0722, b_acc: 100.0\n",
      "750it [00:41, 18.06it/s] Epoch: 10 | b_loss: 0.0259, b_acc: 100.0\n",
      "1000it [00:55, 18.06it/s] Epoch: 10 | b_loss: 0.0637, b_acc: 100.0\n",
      "1250it [01:09, 18.05it/s] Epoch: 10 | b_loss: 0.1385, b_acc: 93.75\n",
      "1365it [01:15, 18.07it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 92.47732893652102\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.0043, b_acc: 100.0\n",
      "250it [00:13, 18.02it/s] Epoch: 11 | b_loss: 0.0244, b_acc: 100.0\n",
      "500it [00:27, 18.09it/s] Epoch: 11 | b_loss: 0.0132, b_acc: 100.0\n",
      "750it [00:41, 18.18it/s] Epoch: 11 | b_loss: 0.0960, b_acc: 96.875\n",
      "1000it [00:54, 18.20it/s] Epoch: 11 | b_loss: 0.0823, b_acc: 100.0\n",
      "1250it [01:08, 18.15it/s] Epoch: 11 | b_loss: 0.1089, b_acc: 100.0\n",
      "1365it [01:15, 18.12it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 92.3330585325639\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.0321, b_acc: 100.0\n",
      "250it [00:14, 17.86it/s] Epoch: 12 | b_loss: 0.0699, b_acc: 100.0\n",
      "500it [00:27, 17.88it/s] Epoch: 12 | b_loss: 0.0872, b_acc: 96.875\n",
      "750it [00:41, 17.88it/s] Epoch: 12 | b_loss: 0.0148, b_acc: 100.0\n",
      "1000it [00:55, 17.88it/s] Epoch: 12 | b_loss: 0.0777, b_acc: 96.875\n",
      "1250it [01:10, 17.85it/s] Epoch: 12 | b_loss: 0.0349, b_acc: 100.0\n",
      "1365it [01:16, 17.86it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 92.31244847485573\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.1406, b_acc: 96.875\n",
      "250it [00:13, 17.93it/s] Epoch: 13 | b_loss: 0.0516, b_acc: 96.875\n",
      "500it [00:27, 17.91it/s] Epoch: 13 | b_loss: 0.0271, b_acc: 100.0\n",
      "750it [00:41, 17.93it/s] Epoch: 13 | b_loss: 0.0239, b_acc: 100.0\n",
      "1000it [00:55, 17.89it/s] Epoch: 13 | b_loss: 0.0488, b_acc: 100.0\n",
      "1250it [01:09, 17.88it/s] Epoch: 13 | b_loss: 0.0334, b_acc: 100.0\n",
      "1365it [01:16, 17.90it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 92.31244847485573\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.0789, b_acc: 96.875\n",
      "250it [00:13, 18.06it/s] Epoch: 14 | b_loss: 0.0211, b_acc: 100.0\n",
      "500it [00:27, 18.12it/s] Epoch: 14 | b_loss: 0.0760, b_acc: 96.875\n",
      "750it [00:41, 18.16it/s] Epoch: 14 | b_loss: 0.0059, b_acc: 100.0\n",
      "1000it [00:55, 18.14it/s] Epoch: 14 | b_loss: 0.0172, b_acc: 100.0\n",
      "1250it [01:09, 18.09it/s] Epoch: 14 | b_loss: 0.0109, b_acc: 100.0\n",
      "1365it [01:15, 18.09it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 92.47732893652102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, cnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:15:31.973411Z",
     "start_time": "2018-08-04T00:15:31.889847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type SimpleCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, DATA_PATH/'models/cnn_es128_knum100_ksz345_90d8acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:49:48.600967Z",
     "start_time": "2018-08-01T18:49:48.598965Z"
    }
   },
   "source": [
    "##### Implementation\n",
    "- Disable dropout during test time (proper eval)+\n",
    "- Try a properly tuned model\n",
    "    - seems to get 92.47% acc, high variance (overfitting) on training data\n",
    "    - might need a bigger batch size\n",
    "- Try learning rate finder\n",
    "- Learning rate cosine annealing\n",
    "- SGD with restarts\n",
    "- Try to predict multiple labels\n",
    "\n",
    "##### Analysis\n",
    "+ Can also check how balanced the classes are+\n",
    "    - Rework unbalanced classes or set class weights\n",
    "+ Try a simple shallow learning model+\n",
    "    - 94.5% accuracy, without fiddling with hyperparams and models much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:51:22.772369Z",
     "start_time": "2018-08-02T20:51:22.730846Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-5, random_state=42,\n",
    "                                           max_iter=25, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.107962Z",
     "start_time": "2018-08-02T20:51:23.108451Z"
    }
   },
   "outputs": [],
   "source": [
    "text_clf.fit(train_texts, train_labels)  \n",
    "predicted = text_clf.predict(val_texts)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.115468Z",
     "start_time": "2018-08-02T20:55:00.109964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453833470733718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == np.asarray(val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "43px",
    "left": "1548px",
    "right": "20px",
    "top": "118px",
    "width": "302px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
