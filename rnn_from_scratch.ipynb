{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:23:12.078360Z",
     "start_time": "2018-08-02T20:22:55.228173Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:23:12.083866Z",
     "start_time": "2018-08-02T20:23:12.080362Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('DATA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset properties, inspection, tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:23:12.537175Z",
     "start_time": "2018-08-02T20:23:12.086366Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'x_and_y_cleaned.pkl'\n",
    "with open(DATA_PATH/DATASET_NAME, 'rb') as f:\n",
    "    articles, categories = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:23:12.545182Z",
     "start_time": "2018-08-02T20:23:12.538677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label None as 'none'\n",
    "categories = ['none' if not x else x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:23:12.573202Z",
     "start_time": "2018-08-02T20:23:12.547183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48514\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "CLASSES = sorted(list(set(categories)))\n",
    "ARTICLE_COUNT = len(articles)\n",
    "CLASS_COUNT = len(CLASSES)\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "MAX_SIZE = 250\n",
    "\n",
    "print(ARTICLE_COUNT)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:25:15.634508Z",
     "start_time": "2018-08-02T20:25:15.622498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uudised/eesti', 16451),\n",
       " ('melu/elu', 5883),\n",
       " ('uudised/maailm', 4285),\n",
       " ('uudised/krimi', 2211),\n",
       " ('televeeb/tvuudised', 1462),\n",
       " ('arvamus/kommentaar', 1342),\n",
       " ('naine/naised', 1163),\n",
       " ('naine/suhted', 1155),\n",
       " ('melu/seltskond', 969),\n",
       " ('sport/jalgpall', 885),\n",
       " ('naine/ilu', 817),\n",
       " ('uudised/kiiksud', 544),\n",
       " ('sport/korvpall', 541),\n",
       " ('tervis/keha', 502),\n",
       " ('blogid/londonilustiblogi', 480),\n",
       " ('uudised/ilm', 461),\n",
       " ('arvamus/juhtkiri', 454),\n",
       " ('sport/varia', 413),\n",
       " ('raha/kodu', 353),\n",
       " ('meedia/galeriid', 334),\n",
       " ('arvamus/repliik', 324),\n",
       " ('melu/saund', 323),\n",
       " ('melu/sunagukolab', 322),\n",
       " ('sport/kergejoustik', 316),\n",
       " ('meedia/videod', 315)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class balance check:\n",
    "freq = Counter(o for o in categories)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:45:56.198864Z",
     "start_time": "2018-08-01T18:45:56.192361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiaeri', 'arvamus', 'arvamus/intervjuu', 'arvamus/juhtkiri', 'arvamus/karikatuur', 'arvamus/kommentaar', 'arvamus/koomiks', 'arvamus/lugejakiri', 'arvamus/nadalatipud', 'arvamus/repliik', 'arvamus/seisukoht', 'blogid/avastaeestimaad', 'blogid/aveameerikas', 'blogid/filmiblogi', 'blogid/hollandiblogi', 'blogid/indoneesiablogi', 'blogid/jumestusblogi', 'blogid/korvpallimm', 'blogid/lehesaba', 'blogid/londonilustiblogi', 'blogid/malluka', 'blogid/meistriteblogi', 'blogid/moeajakiri', 'blogid/moekeeris', 'blogid/motteid', 'blogid/muusikablogi', 'blogid/opetajablogi', 'blogid/psyhholoogiablogi', 'blogid/pulmablogi', 'blogid/raamatublogi', 'blogid/raha', 'blogid/seljakotigablogi', 'blogid/spordiblogi', 'blogid/teleblogi', 'blogid/trenniblogi', 'blogid/valdojahilo', 'blogid/yksikvanem', 'eestinaine/elud-inimesed', 'eriline/horoskoop', 'eriline/mystika', 'joulud', 'kroonika/eesti', 'lemmikloom', 'linnaleht/arvamus', 'linnaleht/dilaila', 'linnaleht/karikatuur', 'linnaleht/kodusedlood', 'linnaleht/paevateema', 'linnaleht/parnu', 'linnaleht/persoon', 'linnaleht/sport', 'linnaleht/tallinn', 'linnaleht/tarbija', 'linnaleht/tartu', 'linnaleht/toimetajaveerg', 'linnaleht/vabaaeg', 'meedia', 'meedia/galeriid', 'meedia/videod', 'mees/auto', 'mehele/reis', 'mehele/tehnika', 'melu/eestitop', 'melu/elu', 'melu/eurovision', 'melu/film', 'melu/saund', 'melu/saund/noorteband', 'melu/saund/noorteband/galeriid', 'melu/saund/noorteband/osalejad', 'melu/seltskond', 'melu/sunagukolab', 'naile/ilu', 'naine', 'naine/ilu', 'naine/naised', 'naine/stella', 'naine/suhted', 'naine/toit', 'none', 'oltv/ilukool', 'oltv/sporttv', 'oltv/uudistv', 'pokker', 'raha', 'raha/kodu', 'raha/rahakott', 'raha/tarbija', 'raha/tehnika', 'sport', 'sport/automoto', 'sport/doping', 'sport/hoki', 'sport/jalgpall', 'sport/jalgrattasport', 'sport/kasipall', 'sport/kergejoustik', 'sport/korvpall', 'sport/korvpallimm', 'sport/maadlus', 'sport/meistriteliiga', 'sport/mm2014', 'sport/muu', 'sport/nba', 'sport/nfl', 'sport/olympia', 'sport/soudmine', 'sport/talisport', 'sport/tantsutydrukud', 'sport/tennis', 'sport/ujumine', 'sport/varia', 'sport/vehklemine', 'sport/vorkpall', 'sport/vormel', 'televeeb/tvuudised', 'tervis', 'tervis/eakad', 'tervis/heanou', 'tervis/hygieen', 'tervis/keha', 'tervis/kysimus', 'tervis/lapsed', 'tervis/meeled', 'tervis/raamat', 'tervis/rasedus', 'tervis/toitumine', 'tervis/treenimine', 'tervis/uudised', 'uudised', 'uudised/eesti', 'uudised/ilm', 'uudised/kiiksud', 'uudised/krimi', 'uudised/maailm', 'uudised/ol70', 'uudised/presidendiball', 'uudised/valimised']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:19:48.069841Z",
     "start_time": "2018-07-29T21:19:48.058332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:  Kas parima aastavahetuse programmi pani eetrisse ETV, Kanal 2 või hoopis TV3? ETVst näegid vaatajad saateid \"V ...\n",
      "CATEGORY:  televeeb/tvuudised\n"
     ]
    }
   ],
   "source": [
    "# Dataset examples:\n",
    "index = 0\n",
    "print('ARTICLE: ', articles[index][0:110], '...')\n",
    "print('CATEGORY: ', categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:18:44.131826Z",
     "start_time": "2018-07-29T21:18:41.169277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.0\n",
      "387.0457805994146\n"
     ]
    }
   ],
   "source": [
    "# Get median/average word count\n",
    "print(np.median([len(x.split(' ')) for x in articles]))\n",
    "print(np.mean([len(x.split(' ')) for x in articles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:33.989982Z",
     "start_time": "2018-07-31T12:20:33.893399Z"
    }
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# labels = []\n",
    "# for x in categories:\n",
    "#     y = [0 for x in range(CLASS_COUNT)]\n",
    "#     y[CLASSES.index(x)] = 1\n",
    "#     labels.append(y)\n",
    "\n",
    "# Class index encoding\n",
    "labels = []\n",
    "for x in categories:\n",
    "    y = CLASSES.index(x)\n",
    "    labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:55.175534Z",
     "start_time": "2018-07-31T12:20:54.333043Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(articles, labels, test_size=0.1, random_state=42)\n",
    "pickle.dump([train_texts, val_texts, train_labels, val_labels], open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:45:56.210876Z",
     "start_time": "2018-08-01T18:45:56.200865Z"
    }
   },
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:01.369147Z",
     "start_time": "2018-07-30T13:19:35.308770Z"
    }
   },
   "outputs": [],
   "source": [
    "tok_train = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(train_texts))\n",
    "tok_val = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:18.105637Z",
     "start_time": "2018-07-30T13:25:14.806690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 657926),\n",
       " ('.', 559252),\n",
       " ('\"', 217175),\n",
       " ('ja', 210514),\n",
       " ('on', 197759),\n",
       " ('et', 150766),\n",
       " ('ei', 106727),\n",
       " ('kui', 74991),\n",
       " ('ta', 66639),\n",
       " ('ka', 58212),\n",
       " ('oli', 51101),\n",
       " ('oma', 46727),\n",
       " ('-', 46020),\n",
       " ('ning', 45314),\n",
       " ('see', 45285),\n",
       " ('xbos', 43662),\n",
       " ('xfld', 43662),\n",
       " ('0', 42597),\n",
       " ('aga', 38936),\n",
       " ('t_up', 31812),\n",
       " ('mis', 31436),\n",
       " ('ma', 30478),\n",
       " ('siis', 29830),\n",
       " ('kes', 29218),\n",
       " ('tema', 28739)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_train for p in o)\n",
    "print(len(tok_train))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:32.945314Z",
     "start_time": "2018-07-30T13:25:32.940310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xbos', 'vehklemisliidu', 'president', ',', 'riigikogu', 'liige', 'margus', 'hanson', 'tõdes', ',', 'et', 'naiskond', 'vehkles', 'kaunilt', 'kuni', 'finaalini', '.', '\"', 'naised', 'olid', 'väga', 'tublid', '.', 'meil', 'on', 'noor', ',', 'perspektiivikas', 'ja', 'arenev', 'võistkond', ':', 'teise', 'kohaga', 'tuleb', 'igati', 'rahul', 'olla', ',', 'sest', 'ega', 'jõu', 'ja', 'võimu', 'vastu', 'ei', 'saa', '!', '\"', 'hanson', 'lisas', ',', 'et', 'teda', 'rõõmustab', 'sten', 'priinitsa', 'individuaalturniiril', 'saadud', 'kaheksas', 'koht', ',', 'millega', 'mees', 'suurendab', 'ka', 't_up', 'eok', 'toetusraha', '.', '\"', 'meie', 'vehklejad', 'on', 'tõestanud', ',', 'et', 'neid', 'saab', 'usaldada', '.', 'sportlased', 'seavad', 'kõrged', 'sihid', 'ja', 'on', 'võimelised', 'neid', 'täitma', ';', '\"', 'kinnitas', 'ta', '.', 'ühtlasi', 'märkis', 'hanson', ',', 'et', 'suur', 'on', 'treener', 'igor', 'tšikinjovi', 'panus', '.', '\"', 'ta', 'on', 'toonud', 'värsket', 'verd', 'ja', 'hingamist', '.', 'see', 'on', 'hästi', 'mõjunud', '.', '\"', 'xfld', 'tk_wrep', '151', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:48.253589Z",
     "start_time": "2018-07-30T13:25:47.768744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 72534),\n",
       " ('.', 62293),\n",
       " ('\"', 23741),\n",
       " ('ja', 23599),\n",
       " ('on', 21847),\n",
       " ('et', 16600),\n",
       " ('ei', 11625),\n",
       " ('kui', 8402),\n",
       " ('ta', 7294),\n",
       " ('ka', 6594),\n",
       " ('oli', 5541),\n",
       " ('ning', 5219),\n",
       " ('oma', 5142),\n",
       " ('-', 5101),\n",
       " ('see', 4893),\n",
       " ('xbos', 4852),\n",
       " ('xfld', 4852),\n",
       " ('0', 4743),\n",
       " ('aga', 4345),\n",
       " ('mis', 3589),\n",
       " ('t_up', 3475),\n",
       " ('ma', 3323),\n",
       " ('tema', 3264),\n",
       " ('eesti', 3248),\n",
       " ('siis', 3235)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_val = Counter(p for o in tok_val for p in o)\n",
    "print(len(tok_val))\n",
    "freq_val.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:09.459592Z",
     "start_time": "2018-07-30T13:26:04.771503Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens/tok_train_pad.npy', tok_train)\n",
    "np.save(DATA_PATH/'tokens/tok_val_pad.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:24.815144Z",
     "start_time": "2018-07-30T13:26:24.558458Z"
    }
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:40.051470Z",
     "start_time": "2018-07-30T13:26:40.007939Z"
    }
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:43:10.741270Z",
     "start_time": "2018-07-30T13:43:06.742874Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lm = np.array([[stoi[o] for o in p] for p in tok_train])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:01.204885Z",
     "start_time": "2018-07-30T13:52:00.857137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pad and crop values\n",
    "train_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in train_lm]\n",
    "val_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in val_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:28.419054Z",
     "start_time": "2018-07-30T13:52:27.621530Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens'/'trn_ids.npy', train_lm_pad) # Oversaved all as padded\n",
    "np.save(DATA_PATH/'tokens'/'val_ids.npy', val_lm_pad)\n",
    "pickle.dump(itos, open(DATA_PATH/'tokens'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:39:33.035979Z",
     "start_time": "2018-08-02T20:39:32.449055Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = pickle.load(open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'rb'))\n",
    "train_lm = np.load(DATA_PATH/'tokens'/'trn_ids.npy')\n",
    "val_lm = np.load(DATA_PATH/'tokens'/'val_ids.npy')\n",
    "itos = pickle.load(open(DATA_PATH/'tokens'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:41:06.002194Z",
     "start_time": "2018-07-30T13:41:05.996690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos Peaminister Taavi Rõivas jätab võimutüli tõttu ära visiidid Leedusse ja Rootsi, teda asendab väliskaubandus- ja ettevõtlusminister Anne Sulling.  Valitsuse pressiesindaja kinnitas pühapäeva pärastlõunal, et Rõivas ei sõida esmaspäeval visiidile Leetu ja Rootsi. Pressiesindaja teatel jäävad visiidid ära \"seoses ametikohustustega Eestis\". Reformierakonna esimees, peaminister Taavi Rõivas pidi esmaspäeval koos teiste Balti riikide valitsusjuhtidega osalema Leedus Klaipedas aset leidval LNG ujuvterminali saabumistseremoonial. Enne tseremooniat pidi aset leidma peaministrite ning Ameerika Ühendriikide esindajate ühine töölõuna. Pärastlõunal pidi Rõivas suunduma edasi Stockholmi, kus toimub Balti- ja Põhjamaade tippkohtumine. Rootsi, Soome, Norra, Islandi, Taani, Eesti, Läti ja Leedu peaministrite kohtumisel räägitakse majanduse olukorrast Euroopas, transatlantilistest suhetest ning Ukrainaga seotud arengutest. Pühapäeval kohtuvad Reformierakonna ja Sotsiaaldemokraatliku Erakonna esimehed, et arutada rahandusminister Jürgen Ligi väljaütlemisest puhkenud tüli. xfld 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:46:21.018841Z",
     "start_time": "2018-07-30T13:46:21.015339Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 425, 524, 658, 2109, 0, 254, 63, 48013, 0, 5, 563, 2, 84, 28902, 0, 5, 53171, 1428, 26646, 3, 64, 755, 588, 438, 2029, 1368, 2, 7, 658, 8, 7061, 661, 4845, 17602, 5, 563, 3, 588, 704, 1070, 48013, 63, 4, 552, 0, 136, 4, 3, 813, 829, 2, 425, 524, 658, 388, 661, 79, 383, 555, 1197, 0, 3403, 5258, 0, 1815, 0, 21, 11591, 0, 0, 3, 105, 50278, 388, 1815, 3905, 31416, 15, 542, 1406, 7017, 3196, 0, 3, 1368, 388, 658, 0, 180, 3805, 2, 45, 638, 50279, 5, 9650, 11347, 3, 563, 2, 322, 2, 954, 2, 5409, 2, 2147, 2, 27, 2, 662, 5, 1109, 31416, 2357, 2275, 3893, 3806, 938, 2, 0, 5920, 15, 12824, 433, 43618, 3, 679, 10646, 813, 5, 7930, 871, 48014, 2, 7, 3819, 1726, 1064, 194, 0, 7214, 1899, 3, 18, 37, 7215, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:21:46.538046Z",
     "start_time": "2018-07-31T12:21:46.534044Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "uudised/eesti\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(CLASSES[train_labels[0]])\n",
    "# print(CLASSES[train_labels[0].index(1)]) # for one hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T19:24:20.762195Z",
     "start_time": "2018-08-01T19:24:20.700655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([43662, 250])\n",
      "y shape torch.Size([43662])\n",
      "x shape torch.Size([4852, 250])\n",
      "y shape torch.Size([4852])\n"
     ]
    }
   ],
   "source": [
    "bs=32\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(train_lm, np.asarray(train_labels))\n",
    "ds_val = TokDataset(val_lm, np.asarray(val_labels))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T19:24:27.554492Z",
     "start_time": "2018-08-01T19:24:27.543975Z"
    }
   },
   "outputs": [],
   "source": [
    "test_values = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T19:24:28.237278Z",
     "start_time": "2018-08-01T19:24:28.232765Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = next(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T19:24:28.564296Z",
     "start_time": "2018-08-01T19:24:28.559788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   17,   444,   111,  ...,    32,     0,     0],\n",
      "        [   17, 19653,     5,  ...,     0,     0,     0],\n",
      "        [   17,   135, 25432,  ...,   715,     0,     0],\n",
      "        ...,\n",
      "        [   17,     4, 17145,  ...,   711,     0,     0],\n",
      "        [   17,  1947,     6,  ...,  4003,     0,     0],\n",
      "        [   17,     0,     8,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feed-forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:22:09.018109Z",
     "start_time": "2018-07-31T12:22:09.013614Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:21.938615Z",
     "start_time": "2018-07-31T15:45:21.929599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, num_l, neurons: List[int], e_size=200):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.input_l = nn.Linear(e_size * input_size, neurons[0])\n",
    "        self.middle_l = nn.ModuleList()\n",
    "        for i in range(num_l):\n",
    "            self.middle_l.append(nn.Linear(neurons[i], neurons[i+1]))\n",
    "        self.output_l = nn.Linear(neurons[-1], num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        i_sz = x.shape[-1]\n",
    "        x = F.relu(self.e(x))\n",
    "        x = x.view(-1,  i_sz * x.shape[-1])\n",
    "        x = F.relu(self.input_l(x))\n",
    "        for l in self.middle_l:\n",
    "            x = F.relu(l(x))\n",
    "        return self.output_l(x) # No softmax for crossentropy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:25.090219Z",
     "start_time": "2018-07-31T15:45:24.863507Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFNN(\n",
      "  (e): Embedding(60000, 200)\n",
      "  (input_l): Linear(in_features=50000, out_features=200, bias=True)\n",
      "  (middle_l): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  )\n",
      "  (output_l): Linear(in_features=20, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = SimpleFNN(MAX_SIZE, max_vocab, CLASS_COUNT, 4, [200, 300, 100, 50, 20]).cuda()\n",
    "print(fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:29.340912Z",
     "start_time": "2018-07-31T15:45:29.335418Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pass through\n",
    "fnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T14:01:47.590476Z",
     "start_time": "2018-08-01T14:01:47.574966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(fnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:20:16.021993Z",
     "start_time": "2018-08-01T20:20:16.016500Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, val_dl, crit, opt, verb=250):\n",
    "    for ep in range(epochs):\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            x, y = data\n",
    "            x = x.cuda(); y = y.cuda()\n",
    "\n",
    "            y_h = model(x)\n",
    "            loss = crit(y_h, y)\n",
    "            \n",
    "            # For accuracy\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y.size(0)\n",
    "            correct += (torch.argmax(y_h, 1) == y).sum().item()\n",
    "\n",
    "            if i % verb == 0:\n",
    "                print(f' Epoch: {ep} | b_loss: {loss.item():.{4}f}, b_acc: {100 * correct / total}')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Validate\n",
    "        val_correct = 0\n",
    "        for i, data_val in enumerate(val_dl):\n",
    "            x_val, y_val = data_val\n",
    "            x_val = x_val.cuda(); y_val = y_val.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_h_val = model(x_val)\n",
    "                val_correct += (torch.argmax(y_h_val, 1) == y_val).sum().item()\n",
    "        print(f'\\nEPOCH {ep} - Val acc: {100 * val_correct / len(val_dl.dataset)}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:03:03.198248Z",
     "start_time": "2018-08-01T20:03:03.191744Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/model.py\n",
    "# https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "# Draft implementation\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, e_size=200, k_num=16, k_sizes=[3, 6, 9, 12]):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, k_num, (k, e_size)) for k in k_sizes])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output_l = nn.Linear(len(k_sizes)*k_num, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.e(x)  # (N, W, D)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] \n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        return self.output_l(x)\n",
    "\n",
    "    \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:03:03.527113Z",
     "start_time": "2018-08-01T20:03:03.383514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (e): Embedding(60000, 200)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 200), stride=(1, 1))\n",
      "    (1): Conv2d(1, 16, kernel_size=(6, 200), stride=(1, 1))\n",
      "    (2): Conv2d(1, 16, kernel_size=(9, 200), stride=(1, 1))\n",
      "    (3): Conv2d(1, 16, kernel_size=(12, 200), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (output_l): Linear(in_features=64, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = SimpleCNN(MAX_SIZE, max_vocab, CLASS_COUNT).cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:03:03.557635Z",
     "start_time": "2018-08-01T20:03:03.551130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:03:06.098327Z",
     "start_time": "2018-08-01T20:03:06.095324Z"
    }
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(cnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:16:56.186474Z",
     "start_time": "2018-08-01T20:14:55.719212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | loss: 0.5625, acc: 84.375\n",
      "245it [00:04, 58.76it/s] Epoch: 0 | loss: 0.4624, acc: 87.5\n",
      "496it [00:08, 58.01it/s] Epoch: 0 | loss: 0.4346, acc: 90.625\n",
      "746it [00:12, 58.09it/s] Epoch: 0 | loss: 0.1507, acc: 96.875\n",
      "999it [00:17, 58.36it/s] Epoch: 0 | loss: 0.0688, acc: 96.875\n",
      "1248it [00:21, 58.46it/s] Epoch: 0 | loss: 0.3629, acc: 87.5\n",
      "1365it [00:23, 58.49it/s]\n",
      "Val acc: 82.60511129431163\n",
      "0it [00:00, ?it/s] Epoch: 1 | loss: 0.3506, acc: 87.5\n",
      "248it [00:04, 58.93it/s] Epoch: 1 | loss: 0.4053, acc: 87.5\n",
      "496it [00:08, 57.93it/s] Epoch: 1 | loss: 0.3709, acc: 90.625\n",
      "749it [00:12, 57.85it/s] Epoch: 1 | loss: 0.3010, acc: 87.5\n",
      "998it [00:17, 57.80it/s] Epoch: 1 | loss: 0.5014, acc: 84.375\n",
      "1249it [00:21, 57.82it/s] Epoch: 1 | loss: 0.2756, acc: 90.625\n",
      "1365it [00:23, 57.75it/s]\n",
      "Val acc: 83.0997526793075\n",
      "0it [00:00, ?it/s] Epoch: 2 | loss: 0.3568, acc: 87.5\n",
      "249it [00:04, 58.10it/s] Epoch: 2 | loss: 0.1823, acc: 96.875\n",
      "495it [00:08, 58.52it/s] Epoch: 2 | loss: 0.2342, acc: 96.875\n",
      "750it [00:12, 58.62it/s] Epoch: 2 | loss: 0.2500, acc: 90.625\n",
      "998it [00:17, 58.67it/s] Epoch: 2 | loss: 0.5642, acc: 87.5\n",
      "1246it [00:21, 58.60it/s] Epoch: 2 | loss: 0.3105, acc: 87.5\n",
      "1365it [00:23, 58.46it/s]\n",
      "Val acc: 83.05853256389118\n",
      "0it [00:00, ?it/s] Epoch: 3 | loss: 0.4036, acc: 87.5\n",
      "249it [00:04, 58.55it/s] Epoch: 3 | loss: 0.1841, acc: 96.875\n",
      "500it [00:08, 58.63it/s] Epoch: 3 | loss: 0.6411, acc: 87.5\n",
      "745it [00:12, 58.64it/s] Epoch: 3 | loss: 0.2351, acc: 93.75\n",
      "998it [00:17, 58.58it/s] Epoch: 3 | loss: 0.3459, acc: 87.5\n",
      "1248it [00:21, 58.43it/s] Epoch: 3 | loss: 0.5789, acc: 90.625\n",
      "1365it [00:23, 58.47it/s]\n",
      "Val acc: 84.25391591096455\n",
      "0it [00:00, ?it/s] Epoch: 4 | loss: 0.2330, acc: 96.875\n",
      "247it [00:04, 57.62it/s] Epoch: 4 | loss: 0.6763, acc: 84.375\n",
      "499it [00:08, 56.93it/s] Epoch: 4 | loss: 0.1818, acc: 93.75\n",
      "745it [00:13, 56.54it/s] Epoch: 4 | loss: 0.1427, acc: 93.75\n",
      "997it [00:17, 56.51it/s] Epoch: 4 | loss: 0.1863, acc: 93.75\n",
      "1246it [00:21, 56.85it/s] Epoch: 4 | loss: 0.0525, acc: 96.875\n",
      "1365it [00:23, 57.02it/s]\n",
      "Val acc: 84.72794723825227\n"
     ]
    }
   ],
   "source": [
    "fit(5, cnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:49:48.600967Z",
     "start_time": "2018-08-01T18:49:48.598965Z"
    }
   },
   "source": [
    "##### Implementation\n",
    "- Disable dropout during test time\n",
    "- Try a properly tuned model\n",
    "- Try learning rate finder\n",
    "- Learning rate cosine annealing\n",
    "- SGD with restarts\n",
    "- Try to predict multiple labels\n",
    "\n",
    "##### Analysis\n",
    "+ Can also check how balanced the classes are\n",
    "    - Rework unbalanced classes or set class weights\n",
    "+ Try a simple shallow learning model\n",
    "    - 94.5% accuracy, without fiddling with hyperparams and models much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:51:22.772369Z",
     "start_time": "2018-08-02T20:51:22.730846Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-5, random_state=42,\n",
    "                                           max_iter=25, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.107962Z",
     "start_time": "2018-08-02T20:51:23.108451Z"
    }
   },
   "outputs": [],
   "source": [
    "text_clf.fit(train_texts, train_labels)  \n",
    "predicted = text_clf.predict(val_texts)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.115468Z",
     "start_time": "2018-08-02T20:55:00.109964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453833470733718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == np.asarray(val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "43px",
    "left": "1548px",
    "right": "20px",
    "top": "118px",
    "width": "302px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
