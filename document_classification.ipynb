{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:27:53.642716Z",
     "start_time": "2018-08-08T17:27:53.639224Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:14:24.760054Z",
     "start_time": "2018-08-08T17:14:24.756552Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('DATA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset properties, inspection, tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:14:25.247078Z",
     "start_time": "2018-08-08T17:14:24.762056Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'x_and_y_cleaned.pkl'\n",
    "with open(DATA_PATH/DATASET_NAME, 'rb') as f:\n",
    "    articles, categories = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:14:25.253583Z",
     "start_time": "2018-08-08T17:14:25.248579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label None as 'none'\n",
    "categories = ['none' if not x else x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:14:25.276600Z",
     "start_time": "2018-08-08T17:14:25.255585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48514\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "CLASSES = sorted(list(set(categories)))\n",
    "ARTICLE_COUNT = len(articles)\n",
    "CLASS_COUNT = len(CLASSES)\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "MAX_SIZE = 250\n",
    "\n",
    "MAX_VOCAB = 60000\n",
    "min_freq = 5\n",
    "\n",
    "print(ARTICLE_COUNT)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.557621Z",
     "start_time": "2018-08-05T15:24:00.539608Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uudised/eesti', 16451),\n",
       " ('melu/elu', 5883),\n",
       " ('uudised/maailm', 4285),\n",
       " ('uudised/krimi', 2211),\n",
       " ('televeeb/tvuudised', 1462),\n",
       " ('arvamus/kommentaar', 1342),\n",
       " ('naine/naised', 1163),\n",
       " ('naine/suhted', 1155),\n",
       " ('melu/seltskond', 969),\n",
       " ('sport/jalgpall', 885),\n",
       " ('naine/ilu', 817),\n",
       " ('uudised/kiiksud', 544),\n",
       " ('sport/korvpall', 541),\n",
       " ('tervis/keha', 502),\n",
       " ('blogid/londonilustiblogi', 480),\n",
       " ('uudised/ilm', 461),\n",
       " ('arvamus/juhtkiri', 454),\n",
       " ('sport/varia', 413),\n",
       " ('raha/kodu', 353),\n",
       " ('meedia/galeriid', 334),\n",
       " ('arvamus/repliik', 324),\n",
       " ('melu/saund', 323),\n",
       " ('melu/sunagukolab', 322),\n",
       " ('sport/kergejoustik', 316),\n",
       " ('meedia/videod', 315)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class balance check:\n",
    "freq = Counter(o for o in categories)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.568629Z",
     "start_time": "2018-08-05T15:24:00.559622Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiaeri', 'arvamus', 'arvamus/intervjuu', 'arvamus/juhtkiri', 'arvamus/karikatuur', 'arvamus/kommentaar', 'arvamus/koomiks', 'arvamus/lugejakiri', 'arvamus/nadalatipud', 'arvamus/repliik', 'arvamus/seisukoht', 'blogid/avastaeestimaad', 'blogid/aveameerikas', 'blogid/filmiblogi', 'blogid/hollandiblogi', 'blogid/indoneesiablogi', 'blogid/jumestusblogi', 'blogid/korvpallimm', 'blogid/lehesaba', 'blogid/londonilustiblogi', 'blogid/malluka', 'blogid/meistriteblogi', 'blogid/moeajakiri', 'blogid/moekeeris', 'blogid/motteid', 'blogid/muusikablogi', 'blogid/opetajablogi', 'blogid/psyhholoogiablogi', 'blogid/pulmablogi', 'blogid/raamatublogi', 'blogid/raha', 'blogid/seljakotigablogi', 'blogid/spordiblogi', 'blogid/teleblogi', 'blogid/trenniblogi', 'blogid/valdojahilo', 'blogid/yksikvanem', 'eestinaine/elud-inimesed', 'eriline/horoskoop', 'eriline/mystika', 'joulud', 'kroonika/eesti', 'lemmikloom', 'linnaleht/arvamus', 'linnaleht/dilaila', 'linnaleht/karikatuur', 'linnaleht/kodusedlood', 'linnaleht/paevateema', 'linnaleht/parnu', 'linnaleht/persoon', 'linnaleht/sport', 'linnaleht/tallinn', 'linnaleht/tarbija', 'linnaleht/tartu', 'linnaleht/toimetajaveerg', 'linnaleht/vabaaeg', 'meedia', 'meedia/galeriid', 'meedia/videod', 'mees/auto', 'mehele/reis', 'mehele/tehnika', 'melu/eestitop', 'melu/elu', 'melu/eurovision', 'melu/film', 'melu/saund', 'melu/saund/noorteband', 'melu/saund/noorteband/galeriid', 'melu/saund/noorteband/osalejad', 'melu/seltskond', 'melu/sunagukolab', 'naile/ilu', 'naine', 'naine/ilu', 'naine/naised', 'naine/stella', 'naine/suhted', 'naine/toit', 'none', 'oltv/ilukool', 'oltv/sporttv', 'oltv/uudistv', 'pokker', 'raha', 'raha/kodu', 'raha/rahakott', 'raha/tarbija', 'raha/tehnika', 'sport', 'sport/automoto', 'sport/doping', 'sport/hoki', 'sport/jalgpall', 'sport/jalgrattasport', 'sport/kasipall', 'sport/kergejoustik', 'sport/korvpall', 'sport/korvpallimm', 'sport/maadlus', 'sport/meistriteliiga', 'sport/mm2014', 'sport/muu', 'sport/nba', 'sport/nfl', 'sport/olympia', 'sport/soudmine', 'sport/talisport', 'sport/tantsutydrukud', 'sport/tennis', 'sport/ujumine', 'sport/varia', 'sport/vehklemine', 'sport/vorkpall', 'sport/vormel', 'televeeb/tvuudised', 'tervis', 'tervis/eakad', 'tervis/heanou', 'tervis/hygieen', 'tervis/keha', 'tervis/kysimus', 'tervis/lapsed', 'tervis/meeled', 'tervis/raamat', 'tervis/rasedus', 'tervis/toitumine', 'tervis/treenimine', 'tervis/uudised', 'uudised', 'uudised/eesti', 'uudised/ilm', 'uudised/kiiksud', 'uudised/krimi', 'uudised/maailm', 'uudised/ol70', 'uudised/presidendiball', 'uudised/valimised']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.584644Z",
     "start_time": "2018-08-05T15:24:00.570631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:  Kas parima aastavahetuse programmi pani eetrisse ETV, Kanal 2 või hoopis TV3? ETVst näegid vaatajad saateid \"V ...\n",
      "CATEGORY:  televeeb/tvuudised\n"
     ]
    }
   ],
   "source": [
    "# Dataset examples:\n",
    "index = 0\n",
    "print('ARTICLE: ', articles[index][0:110], '...')\n",
    "print('CATEGORY: ', categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:18:44.131826Z",
     "start_time": "2018-07-29T21:18:41.169277Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.0\n",
      "387.0457805994146\n"
     ]
    }
   ],
   "source": [
    "# Get median/average word count\n",
    "print(np.median([len(x.split(' ')) for x in articles]))\n",
    "print(np.mean([len(x.split(' ')) for x in articles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:33.989982Z",
     "start_time": "2018-07-31T12:20:33.893399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# labels = []\n",
    "# for x in categories:\n",
    "#     y = [0 for x in range(CLASS_COUNT)]\n",
    "#     y[CLASSES.index(x)] = 1\n",
    "#     labels.append(y)\n",
    "\n",
    "# Class index encoding\n",
    "labels = []\n",
    "for x in categories:\n",
    "    y = CLASSES.index(x)\n",
    "    labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:55.175534Z",
     "start_time": "2018-07-31T12:20:54.333043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(articles, labels, test_size=0.1, random_state=42)\n",
    "pickle.dump([train_texts, val_texts, train_labels, val_labels], open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:01.369147Z",
     "start_time": "2018-07-30T13:19:35.308770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tok_train = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(train_texts))\n",
    "tok_val = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:18.105637Z",
     "start_time": "2018-07-30T13:25:14.806690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 657926),\n",
       " ('.', 559252),\n",
       " ('\"', 217175),\n",
       " ('ja', 210514),\n",
       " ('on', 197759),\n",
       " ('et', 150766),\n",
       " ('ei', 106727),\n",
       " ('kui', 74991),\n",
       " ('ta', 66639),\n",
       " ('ka', 58212),\n",
       " ('oli', 51101),\n",
       " ('oma', 46727),\n",
       " ('-', 46020),\n",
       " ('ning', 45314),\n",
       " ('see', 45285),\n",
       " ('xbos', 43662),\n",
       " ('xfld', 43662),\n",
       " ('0', 42597),\n",
       " ('aga', 38936),\n",
       " ('t_up', 31812),\n",
       " ('mis', 31436),\n",
       " ('ma', 30478),\n",
       " ('siis', 29830),\n",
       " ('kes', 29218),\n",
       " ('tema', 28739)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_train for p in o)\n",
    "print(len(tok_train))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:32.945314Z",
     "start_time": "2018-07-30T13:25:32.940310Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xbos', 'vehklemisliidu', 'president', ',', 'riigikogu', 'liige', 'margus', 'hanson', 'tõdes', ',', 'et', 'naiskond', 'vehkles', 'kaunilt', 'kuni', 'finaalini', '.', '\"', 'naised', 'olid', 'väga', 'tublid', '.', 'meil', 'on', 'noor', ',', 'perspektiivikas', 'ja', 'arenev', 'võistkond', ':', 'teise', 'kohaga', 'tuleb', 'igati', 'rahul', 'olla', ',', 'sest', 'ega', 'jõu', 'ja', 'võimu', 'vastu', 'ei', 'saa', '!', '\"', 'hanson', 'lisas', ',', 'et', 'teda', 'rõõmustab', 'sten', 'priinitsa', 'individuaalturniiril', 'saadud', 'kaheksas', 'koht', ',', 'millega', 'mees', 'suurendab', 'ka', 't_up', 'eok', 'toetusraha', '.', '\"', 'meie', 'vehklejad', 'on', 'tõestanud', ',', 'et', 'neid', 'saab', 'usaldada', '.', 'sportlased', 'seavad', 'kõrged', 'sihid', 'ja', 'on', 'võimelised', 'neid', 'täitma', ';', '\"', 'kinnitas', 'ta', '.', 'ühtlasi', 'märkis', 'hanson', ',', 'et', 'suur', 'on', 'treener', 'igor', 'tšikinjovi', 'panus', '.', '\"', 'ta', 'on', 'toonud', 'värsket', 'verd', 'ja', 'hingamist', '.', 'see', 'on', 'hästi', 'mõjunud', '.', '\"', 'xfld', 'tk_wrep', '151', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:48.253589Z",
     "start_time": "2018-07-30T13:25:47.768744Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 72534),\n",
       " ('.', 62293),\n",
       " ('\"', 23741),\n",
       " ('ja', 23599),\n",
       " ('on', 21847),\n",
       " ('et', 16600),\n",
       " ('ei', 11625),\n",
       " ('kui', 8402),\n",
       " ('ta', 7294),\n",
       " ('ka', 6594),\n",
       " ('oli', 5541),\n",
       " ('ning', 5219),\n",
       " ('oma', 5142),\n",
       " ('-', 5101),\n",
       " ('see', 4893),\n",
       " ('xbos', 4852),\n",
       " ('xfld', 4852),\n",
       " ('0', 4743),\n",
       " ('aga', 4345),\n",
       " ('mis', 3589),\n",
       " ('t_up', 3475),\n",
       " ('ma', 3323),\n",
       " ('tema', 3264),\n",
       " ('eesti', 3248),\n",
       " ('siis', 3235)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_val = Counter(p for o in tok_val for p in o)\n",
    "print(len(tok_val))\n",
    "freq_val.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:09.459592Z",
     "start_time": "2018-07-30T13:26:04.771503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens/tok_train_pad.npy', tok_train)\n",
    "np.save(DATA_PATH/'tokens/tok_val_pad.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:24.815144Z",
     "start_time": "2018-07-30T13:26:24.558458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(MAX_VOCAB) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:40.051470Z",
     "start_time": "2018-07-30T13:26:40.007939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:43:10.741270Z",
     "start_time": "2018-07-30T13:43:06.742874Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_lm = np.array([[stoi[o] for o in p] for p in tok_train])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:01.204885Z",
     "start_time": "2018-07-30T13:52:00.857137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pad and crop values\n",
    "train_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in train_lm]\n",
    "val_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in val_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:28.419054Z",
     "start_time": "2018-07-30T13:52:27.621530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens'/'trn_ids.npy', train_lm_pad) # Oversaved all as padded\n",
    "np.save(DATA_PATH/'tokens'/'val_ids.npy', val_lm_pad)\n",
    "pickle.dump(itos, open(DATA_PATH/'tokens'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:16:00.658098Z",
     "start_time": "2018-08-08T17:16:00.023410Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = pickle.load(open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'rb'))\n",
    "train_lm = np.load(DATA_PATH/'tokens'/'trn_ids.npy')\n",
    "val_lm = np.load(DATA_PATH/'tokens'/'val_ids.npy')\n",
    "itos = pickle.load(open(DATA_PATH/'tokens'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:41:06.002194Z",
     "start_time": "2018-07-30T13:41:05.996690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos Peaminister Taavi Rõivas jätab võimutüli tõttu ära visiidid Leedusse ja Rootsi, teda asendab väliskaubandus- ja ettevõtlusminister Anne Sulling.  Valitsuse pressiesindaja kinnitas pühapäeva pärastlõunal, et Rõivas ei sõida esmaspäeval visiidile Leetu ja Rootsi. Pressiesindaja teatel jäävad visiidid ära \"seoses ametikohustustega Eestis\". Reformierakonna esimees, peaminister Taavi Rõivas pidi esmaspäeval koos teiste Balti riikide valitsusjuhtidega osalema Leedus Klaipedas aset leidval LNG ujuvterminali saabumistseremoonial. Enne tseremooniat pidi aset leidma peaministrite ning Ameerika Ühendriikide esindajate ühine töölõuna. Pärastlõunal pidi Rõivas suunduma edasi Stockholmi, kus toimub Balti- ja Põhjamaade tippkohtumine. Rootsi, Soome, Norra, Islandi, Taani, Eesti, Läti ja Leedu peaministrite kohtumisel räägitakse majanduse olukorrast Euroopas, transatlantilistest suhetest ning Ukrainaga seotud arengutest. Pühapäeval kohtuvad Reformierakonna ja Sotsiaaldemokraatliku Erakonna esimehed, et arutada rahandusminister Jürgen Ligi väljaütlemisest puhkenud tüli. xfld 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:46:21.018841Z",
     "start_time": "2018-07-30T13:46:21.015339Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 425, 524, 658, 2109, 0, 254, 63, 48013, 0, 5, 563, 2, 84, 28902, 0, 5, 53171, 1428, 26646, 3, 64, 755, 588, 438, 2029, 1368, 2, 7, 658, 8, 7061, 661, 4845, 17602, 5, 563, 3, 588, 704, 1070, 48013, 63, 4, 552, 0, 136, 4, 3, 813, 829, 2, 425, 524, 658, 388, 661, 79, 383, 555, 1197, 0, 3403, 5258, 0, 1815, 0, 21, 11591, 0, 0, 3, 105, 50278, 388, 1815, 3905, 31416, 15, 542, 1406, 7017, 3196, 0, 3, 1368, 388, 658, 0, 180, 3805, 2, 45, 638, 50279, 5, 9650, 11347, 3, 563, 2, 322, 2, 954, 2, 5409, 2, 2147, 2, 27, 2, 662, 5, 1109, 31416, 2357, 2275, 3893, 3806, 938, 2, 0, 5920, 15, 12824, 433, 43618, 3, 679, 10646, 813, 5, 7930, 871, 48014, 2, 7, 3819, 1726, 1064, 194, 0, 7214, 1899, 3, 18, 37, 7215, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:21:46.538046Z",
     "start_time": "2018-07-31T12:21:46.534044Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "uudised/eesti\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(CLASSES[train_labels[0]])\n",
    "# print(CLASSES[train_labels[0].index(1)]) # for one hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:16:01.144555Z",
     "start_time": "2018-08-08T17:16:01.079009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([43662, 250])\n",
      "y shape torch.Size([43662])\n",
      "x shape torch.Size([4852, 250])\n",
      "y shape torch.Size([4852])\n"
     ]
    }
   ],
   "source": [
    "bs=128\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(train_lm, np.asarray(train_labels))\n",
    "ds_val = TokDataset(val_lm, np.asarray(val_labels))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:17:41.080698Z",
     "start_time": "2018-08-08T17:17:41.069690Z"
    }
   },
   "outputs": [],
   "source": [
    "test_values = iter(dl)\n",
    "xs, ys = next(test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:28:10.868403Z",
     "start_time": "2018-08-08T17:28:10.861898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, val_dl, crit, opt, verb=250):\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            x, y = data\n",
    "            x = x.cuda(); y = y.cuda()\n",
    "\n",
    "            y_h = model(x)\n",
    "            loss = crit(y_h, y)\n",
    "            \n",
    "            # For accuracy\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y.size(0)\n",
    "            correct += (torch.argmax(y_h, 1) == y).sum().item()\n",
    "\n",
    "            if i % verb == 0:\n",
    "                print(f' Epoch: {ep} | b_loss: {loss.item():.{4}f}, b_acc: {100 * correct / total}')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Validate\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        for i, data_val in enumerate(val_dl):\n",
    "            x_val, y_val = data_val\n",
    "            x_val = x_val.cuda(); y_val = y_val.cuda()\n",
    "            \n",
    "            # .eval() doesn't turn off gradient tracking\n",
    "            with torch.no_grad():\n",
    "                y_h_val = model(x_val)\n",
    "                val_correct += (torch.argmax(y_h_val, 1) == y_val).sum().item()\n",
    "        print(f'\\nEPOCH {ep} - Val acc: {100 * val_correct / len(val_dl.dataset)}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feed-forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:22:09.018109Z",
     "start_time": "2018-07-31T12:22:09.013614Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T12:05:03.579889Z",
     "start_time": "2018-08-06T12:05:03.574886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, num_l, neurons: List[int], e_size=100):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.input_l = nn.Linear(e_size * input_size, neurons[0])\n",
    "        self.middle_l = nn.ModuleList()\n",
    "        for i in range(num_l):\n",
    "            self.middle_l.append(nn.Linear(neurons[i], neurons[i+1]))\n",
    "        self.output_l = nn.Linear(neurons[-1], num_outputs)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        i_sz = x.shape[-1]\n",
    "        x = F.relu(self.e(x))\n",
    "        x = x.view(-1,  i_sz * x.shape[-1])\n",
    "        x = F.relu(self.input_l(x))\n",
    "        for l in self.middle_l:\n",
    "            x = F.relu(self.dropout(l(x)))\n",
    "        return self.output_l(x) # No softmax for crossentropy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T12:05:04.185936Z",
     "start_time": "2018-08-06T12:05:04.055344Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFNN(\n",
      "  (e): Embedding(60000, 100)\n",
      "  (input_l): Linear(in_features=25000, out_features=200, bias=True)\n",
      "  (middle_l): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  )\n",
      "  (output_l): Linear(in_features=20, out_features=138, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = SimpleFNN(MAX_SIZE, MAX_VOCAB, CLASS_COUNT, 4, [200, 300, 100, 50, 20]).cuda()\n",
    "print(fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T12:05:07.373758Z",
     "start_time": "2018-08-06T12:05:07.366752Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pass through\n",
    "fnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T12:11:57.385738Z",
     "start_time": "2018-08-06T12:11:57.382736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(fnn.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T12:22:19.864272Z",
     "start_time": "2018-08-06T12:11:57.998692Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 0.4515, b_acc: 85.9375\n",
      "246it [00:04, 55.67it/s] Epoch: 0 | b_loss: 0.1458, b_acc: 95.3125\n",
      "342it [00:06, 55.55it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 81.18301731244847\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 0.2479, b_acc: 93.75\n",
      "246it [00:04, 56.20it/s] Epoch: 1 | b_loss: 0.3079, b_acc: 92.1875\n",
      "342it [00:06, 55.98it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 81.10057708161582\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 0.3286, b_acc: 89.0625\n",
      "246it [00:04, 55.56it/s] Epoch: 2 | b_loss: 0.3491, b_acc: 90.625\n",
      "342it [00:06, 55.46it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 81.24484748557296\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 0.2795, b_acc: 91.40625\n",
      "246it [00:04, 55.44it/s] Epoch: 3 | b_loss: 0.2152, b_acc: 91.40625\n",
      "342it [00:06, 55.43it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 81.38911788953008\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.2213, b_acc: 93.75\n",
      "246it [00:04, 55.89it/s] Epoch: 4 | b_loss: 0.3165, b_acc: 91.40625\n",
      "342it [00:06, 56.01it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 81.30667765869744\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.2584, b_acc: 91.40625\n",
      "246it [00:04, 56.11it/s] Epoch: 5 | b_loss: 0.1827, b_acc: 94.53125\n",
      "342it [00:06, 56.02it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 81.24484748557296\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.2844, b_acc: 92.1875\n",
      "246it [00:04, 55.89it/s] Epoch: 6 | b_loss: 0.2740, b_acc: 89.84375\n",
      "342it [00:06, 55.92it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 81.47155812036274\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.2333, b_acc: 93.75\n",
      "246it [00:04, 55.91it/s] Epoch: 7 | b_loss: 0.2775, b_acc: 90.625\n",
      "342it [00:06, 55.91it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 81.59521846661171\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.3569, b_acc: 91.40625\n",
      "246it [00:04, 55.99it/s] Epoch: 8 | b_loss: 0.2385, b_acc: 93.75\n",
      "342it [00:06, 55.97it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 81.14179719703215\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.3445, b_acc: 91.40625\n",
      "246it [00:04, 55.85it/s] Epoch: 9 | b_loss: 0.2830, b_acc: 92.1875\n",
      "342it [00:06, 55.84it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 81.71887881286068\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.4079, b_acc: 87.5\n",
      "246it [00:04, 55.95it/s] Epoch: 10 | b_loss: 0.2613, b_acc: 91.40625\n",
      "342it [00:06, 55.86it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 81.47155812036274\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.1554, b_acc: 93.75\n",
      "246it [00:04, 55.61it/s] Epoch: 11 | b_loss: 0.2023, b_acc: 94.53125\n",
      "342it [00:06, 55.65it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 81.36850783182193\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.2436, b_acc: 92.1875\n",
      "246it [00:04, 55.55it/s] Epoch: 12 | b_loss: 0.2039, b_acc: 95.3125\n",
      "342it [00:06, 55.71it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 81.53338829348722\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.2052, b_acc: 93.75\n",
      "246it [00:04, 55.68it/s] Epoch: 13 | b_loss: 0.1828, b_acc: 92.96875\n",
      "342it [00:06, 55.74it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 81.65704863973619\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.3162, b_acc: 90.625\n",
      "246it [00:04, 56.01it/s] Epoch: 14 | b_loss: 0.2488, b_acc: 93.75\n",
      "342it [00:06, 55.96it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 81.63643858202803\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 15 | b_loss: 0.2896, b_acc: 91.40625\n",
      "246it [00:04, 55.78it/s] Epoch: 15 | b_loss: 0.3565, b_acc: 89.0625\n",
      "342it [00:06, 55.73it/s]\n",
      "\n",
      "EPOCH 15 - Val acc: 81.53338829348722\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 16 | b_loss: 0.1933, b_acc: 95.3125\n",
      "246it [00:04, 55.98it/s] Epoch: 16 | b_loss: 0.1207, b_acc: 96.09375\n",
      "342it [00:06, 55.80it/s]\n",
      "\n",
      "EPOCH 16 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 17 | b_loss: 0.2438, b_acc: 91.40625\n",
      "246it [00:04, 55.92it/s] Epoch: 17 | b_loss: 0.3590, b_acc: 87.5\n",
      "342it [00:06, 55.86it/s]\n",
      "\n",
      "EPOCH 17 - Val acc: 81.71887881286068\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 18 | b_loss: 0.1391, b_acc: 95.3125\n",
      "246it [00:04, 56.01it/s] Epoch: 18 | b_loss: 0.2367, b_acc: 92.1875\n",
      "342it [00:06, 55.99it/s]\n",
      "\n",
      "EPOCH 18 - Val acc: 81.73948887056883\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 19 | b_loss: 0.1330, b_acc: 94.53125\n",
      "246it [00:04, 55.79it/s] Epoch: 19 | b_loss: 0.3400, b_acc: 89.84375\n",
      "342it [00:06, 55.87it/s]\n",
      "\n",
      "EPOCH 19 - Val acc: 81.71887881286068\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 20 | b_loss: 0.2155, b_acc: 92.1875\n",
      "246it [00:04, 55.85it/s] Epoch: 20 | b_loss: 0.2959, b_acc: 89.84375\n",
      "342it [00:06, 55.79it/s]\n",
      "\n",
      "EPOCH 20 - Val acc: 81.59521846661171\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 21 | b_loss: 0.1897, b_acc: 92.1875\n",
      "246it [00:04, 55.71it/s] Epoch: 21 | b_loss: 0.2655, b_acc: 89.84375\n",
      "342it [00:06, 55.69it/s]\n",
      "\n",
      "EPOCH 21 - Val acc: 81.53338829348722\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 22 | b_loss: 0.1976, b_acc: 92.1875\n",
      "246it [00:04, 56.02it/s] Epoch: 22 | b_loss: 0.2568, b_acc: 92.1875\n",
      "342it [00:06, 55.97it/s]\n",
      "\n",
      "EPOCH 22 - Val acc: 81.73948887056883\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 23 | b_loss: 0.2032, b_acc: 92.1875\n",
      "246it [00:04, 55.80it/s] Epoch: 23 | b_loss: 0.1471, b_acc: 95.3125\n",
      "342it [00:06, 55.92it/s]\n",
      "\n",
      "EPOCH 23 - Val acc: 81.8631492168178\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 24 | b_loss: 0.1984, b_acc: 96.09375\n",
      "246it [00:04, 55.79it/s] Epoch: 24 | b_loss: 0.1655, b_acc: 93.75\n",
      "342it [00:06, 55.80it/s]\n",
      "\n",
      "EPOCH 24 - Val acc: 81.67765869744436\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 25 | b_loss: 0.1376, b_acc: 95.3125\n",
      "246it [00:04, 55.94it/s] Epoch: 25 | b_loss: 0.3221, b_acc: 89.84375\n",
      "342it [00:06, 55.80it/s]\n",
      "\n",
      "EPOCH 25 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 26 | b_loss: 0.4000, b_acc: 90.625\n",
      "246it [00:04, 56.06it/s] Epoch: 26 | b_loss: 0.2056, b_acc: 92.1875\n",
      "342it [00:06, 56.04it/s]\n",
      "\n",
      "EPOCH 26 - Val acc: 81.84253915910965\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 27 | b_loss: 0.1774, b_acc: 91.40625\n",
      "246it [00:04, 55.82it/s] Epoch: 27 | b_loss: 0.1360, b_acc: 96.09375\n",
      "342it [00:06, 55.84it/s]\n",
      "\n",
      "EPOCH 27 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 28 | b_loss: 0.2224, b_acc: 93.75\n",
      "246it [00:04, 55.65it/s] Epoch: 28 | b_loss: 0.3488, b_acc: 89.0625\n",
      "342it [00:06, 55.60it/s]\n",
      "\n",
      "EPOCH 28 - Val acc: 81.3272877164056\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 29 | b_loss: 0.2424, b_acc: 94.53125\n",
      "246it [00:04, 55.78it/s] Epoch: 29 | b_loss: 0.1818, b_acc: 93.75\n",
      "342it [00:06, 55.70it/s]\n",
      "\n",
      "EPOCH 29 - Val acc: 81.84253915910965\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 30 | b_loss: 0.1313, b_acc: 95.3125\n",
      "246it [00:04, 55.79it/s] Epoch: 30 | b_loss: 0.2607, b_acc: 92.1875\n",
      "342it [00:06, 55.81it/s]\n",
      "\n",
      "EPOCH 30 - Val acc: 81.90436933223413\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 31 | b_loss: 0.2297, b_acc: 94.53125\n",
      "246it [00:04, 55.75it/s] Epoch: 31 | b_loss: 0.1880, b_acc: 93.75\n",
      "342it [00:06, 55.71it/s]\n",
      "\n",
      "EPOCH 31 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 32 | b_loss: 0.2142, b_acc: 92.1875\n",
      "246it [00:04, 55.84it/s] Epoch: 32 | b_loss: 0.2213, b_acc: 92.96875\n",
      "342it [00:06, 55.77it/s]\n",
      "\n",
      "EPOCH 32 - Val acc: 82.0280296784831\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 33 | b_loss: 0.2112, b_acc: 94.53125\n",
      "246it [00:04, 55.69it/s] Epoch: 33 | b_loss: 0.2180, b_acc: 89.0625\n",
      "342it [00:06, 55.63it/s]\n",
      "\n",
      "EPOCH 33 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 34 | b_loss: 0.1821, b_acc: 94.53125\n",
      "246it [00:04, 55.79it/s] Epoch: 34 | b_loss: 0.2747, b_acc: 93.75\n",
      "342it [00:06, 55.87it/s]\n",
      "\n",
      "EPOCH 34 - Val acc: 81.8631492168178\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 35 | b_loss: 0.2485, b_acc: 93.75\n",
      "246it [00:04, 56.01it/s] Epoch: 35 | b_loss: 0.2908, b_acc: 90.625\n",
      "342it [00:06, 55.83it/s]\n",
      "\n",
      "EPOCH 35 - Val acc: 81.82192910140148\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 36 | b_loss: 0.1950, b_acc: 96.09375\n",
      "246it [00:04, 56.02it/s] Epoch: 36 | b_loss: 0.1840, b_acc: 93.75\n",
      "342it [00:06, 56.00it/s]\n",
      "\n",
      "EPOCH 36 - Val acc: 81.63643858202803\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 37 | b_loss: 0.2003, b_acc: 94.53125\n",
      "246it [00:04, 55.75it/s] Epoch: 37 | b_loss: 0.2594, b_acc: 92.1875\n",
      "342it [00:06, 55.79it/s]\n",
      "\n",
      "EPOCH 37 - Val acc: 81.760098928277\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 38 | b_loss: 0.2524, b_acc: 93.75\n",
      "246it [00:04, 56.05it/s] Epoch: 38 | b_loss: 0.1556, b_acc: 95.3125\n",
      "342it [00:06, 55.93it/s]\n",
      "\n",
      "EPOCH 38 - Val acc: 81.51277823577907\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 39 | b_loss: 0.1804, b_acc: 93.75\n",
      "246it [00:04, 55.99it/s] Epoch: 39 | b_loss: 0.0978, b_acc: 96.09375\n",
      "342it [00:06, 56.01it/s]\n",
      "\n",
      "EPOCH 39 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 40 | b_loss: 0.2897, b_acc: 91.40625\n",
      "246it [00:04, 55.85it/s] Epoch: 40 | b_loss: 0.2753, b_acc: 93.75\n",
      "342it [00:06, 55.81it/s]\n",
      "\n",
      "EPOCH 40 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 41 | b_loss: 0.1773, b_acc: 95.3125\n",
      "246it [00:04, 55.66it/s] Epoch: 41 | b_loss: 0.2405, b_acc: 90.625\n",
      "342it [00:06, 55.79it/s]\n",
      "\n",
      "EPOCH 41 - Val acc: 81.73948887056883\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 42 | b_loss: 0.1971, b_acc: 93.75\n",
      "246it [00:04, 56.02it/s] Epoch: 42 | b_loss: 0.1531, b_acc: 96.875\n",
      "342it [00:06, 55.91it/s]\n",
      "\n",
      "EPOCH 42 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 43 | b_loss: 0.1626, b_acc: 94.53125\n",
      "246it [00:04, 56.10it/s] Epoch: 43 | b_loss: 0.1949, b_acc: 93.75\n",
      "342it [00:06, 55.98it/s]\n",
      "\n",
      "EPOCH 43 - Val acc: 81.82192910140148\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 44 | b_loss: 0.2101, b_acc: 92.1875\n",
      "246it [00:04, 55.85it/s] Epoch: 44 | b_loss: 0.3142, b_acc: 92.1875\n",
      "342it [00:06, 55.84it/s]\n",
      "\n",
      "EPOCH 44 - Val acc: 81.40972794723825\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 45 | b_loss: 0.1618, b_acc: 96.875\n",
      "246it [00:04, 55.74it/s] Epoch: 45 | b_loss: 0.2159, b_acc: 91.40625\n",
      "342it [00:06, 55.80it/s]\n",
      "\n",
      "EPOCH 45 - Val acc: 81.71887881286068\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 46 | b_loss: 0.1669, b_acc: 95.3125\n",
      "246it [00:04, 56.11it/s] Epoch: 46 | b_loss: 0.2166, b_acc: 93.75\n",
      "342it [00:06, 55.99it/s]\n",
      "\n",
      "EPOCH 46 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 47 | b_loss: 0.2019, b_acc: 92.96875\n",
      "246it [00:04, 56.02it/s] Epoch: 47 | b_loss: 0.0824, b_acc: 97.65625\n",
      "342it [00:06, 56.07it/s]\n",
      "\n",
      "EPOCH 47 - Val acc: 81.90436933223413\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 48 | b_loss: 0.2233, b_acc: 95.3125\n",
      "246it [00:04, 56.13it/s] Epoch: 48 | b_loss: 0.2022, b_acc: 92.1875\n",
      "342it [00:06, 55.97it/s]\n",
      "\n",
      "EPOCH 48 - Val acc: 81.51277823577907\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 49 | b_loss: 0.2002, b_acc: 91.40625\n",
      "247it [00:04, 56.14it/s] Epoch: 49 | b_loss: 0.1873, b_acc: 92.96875\n",
      "342it [00:06, 55.99it/s]\n",
      "\n",
      "EPOCH 49 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 50 | b_loss: 0.1734, b_acc: 94.53125\n",
      "246it [00:04, 55.85it/s] Epoch: 50 | b_loss: 0.1859, b_acc: 95.3125\n",
      "342it [00:06, 55.95it/s]\n",
      "\n",
      "EPOCH 50 - Val acc: 81.8631492168178\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 51 | b_loss: 0.0740, b_acc: 97.65625\n",
      "246it [00:04, 55.97it/s] Epoch: 51 | b_loss: 0.1070, b_acc: 95.3125\n",
      "342it [00:06, 55.94it/s]\n",
      "\n",
      "EPOCH 51 - Val acc: 81.94558944765045\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 52 | b_loss: 0.2787, b_acc: 93.75\n",
      "246it [00:04, 56.18it/s] Epoch: 52 | b_loss: 0.1223, b_acc: 97.65625\n",
      "342it [00:06, 55.98it/s]\n",
      "\n",
      "EPOCH 52 - Val acc: 81.63643858202803\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 53 | b_loss: 0.2111, b_acc: 92.1875\n",
      "245it [00:04, 55.94it/s] Epoch: 53 | b_loss: 0.1493, b_acc: 96.875\n",
      "342it [00:06, 55.93it/s]\n",
      "\n",
      "EPOCH 53 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 54 | b_loss: 0.3010, b_acc: 92.1875\n",
      "246it [00:04, 55.99it/s] Epoch: 54 | b_loss: 0.2326, b_acc: 93.75\n",
      "342it [00:06, 55.90it/s]\n",
      "\n",
      "EPOCH 54 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 55 | b_loss: 0.1772, b_acc: 94.53125\n",
      "246it [00:04, 56.01it/s] Epoch: 55 | b_loss: 0.2407, b_acc: 91.40625\n",
      "342it [00:06, 55.92it/s]\n",
      "\n",
      "EPOCH 55 - Val acc: 82.06924979389942\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 56 | b_loss: 0.2582, b_acc: 93.75\n",
      "246it [00:04, 56.01it/s] Epoch: 56 | b_loss: 0.2016, b_acc: 94.53125\n",
      "342it [00:06, 55.90it/s]\n",
      "\n",
      "EPOCH 56 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 57 | b_loss: 0.0847, b_acc: 97.65625\n",
      "246it [00:04, 56.03it/s] Epoch: 57 | b_loss: 0.1763, b_acc: 94.53125\n",
      "342it [00:06, 55.99it/s]\n",
      "\n",
      "EPOCH 57 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 58 | b_loss: 0.1659, b_acc: 94.53125\n",
      "246it [00:04, 55.73it/s] Epoch: 58 | b_loss: 0.1606, b_acc: 96.09375\n",
      "342it [00:06, 55.87it/s]\n",
      "\n",
      "EPOCH 58 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 59 | b_loss: 0.2016, b_acc: 92.96875\n",
      "246it [00:04, 55.79it/s] Epoch: 59 | b_loss: 0.1994, b_acc: 92.96875\n",
      "342it [00:06, 55.95it/s]\n",
      "\n",
      "EPOCH 59 - Val acc: 81.69826875515251\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 60 | b_loss: 0.0987, b_acc: 95.3125\n",
      "246it [00:04, 55.75it/s] Epoch: 60 | b_loss: 0.2396, b_acc: 92.1875\n",
      "342it [00:06, 55.82it/s]\n",
      "\n",
      "EPOCH 60 - Val acc: 82.06924979389942\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 61 | b_loss: 0.1677, b_acc: 95.3125\n",
      "246it [00:04, 56.28it/s] Epoch: 61 | b_loss: 0.2083, b_acc: 94.53125\n",
      "342it [00:06, 56.02it/s]\n",
      "\n",
      "EPOCH 61 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 62 | b_loss: 0.1445, b_acc: 95.3125\n",
      "246it [00:04, 56.18it/s] Epoch: 62 | b_loss: 0.1462, b_acc: 95.3125\n",
      "342it [00:06, 56.08it/s]\n",
      "\n",
      "EPOCH 62 - Val acc: 81.57460840890354\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 63 | b_loss: 0.1486, b_acc: 94.53125\n",
      "246it [00:04, 55.94it/s] Epoch: 63 | b_loss: 0.1355, b_acc: 94.53125\n",
      "342it [00:06, 55.94it/s]\n",
      "\n",
      "EPOCH 63 - Val acc: 81.82192910140148\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 64 | b_loss: 0.1972, b_acc: 93.75\n",
      "246it [00:04, 55.86it/s] Epoch: 64 | b_loss: 0.1369, b_acc: 96.09375\n",
      "342it [00:06, 55.82it/s]\n",
      "\n",
      "EPOCH 64 - Val acc: 81.55399835119539\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 65 | b_loss: 0.2207, b_acc: 92.96875\n",
      "246it [00:04, 56.20it/s] Epoch: 65 | b_loss: 0.2417, b_acc: 92.1875\n",
      "342it [00:06, 56.12it/s]\n",
      "\n",
      "EPOCH 65 - Val acc: 81.98680956306677\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 66 | b_loss: 0.2692, b_acc: 91.40625\n",
      "246it [00:04, 55.74it/s] Epoch: 66 | b_loss: 0.0811, b_acc: 98.4375\n",
      "342it [00:06, 55.74it/s]\n",
      "\n",
      "EPOCH 66 - Val acc: 81.71887881286068\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 67 | b_loss: 0.1455, b_acc: 96.09375\n",
      "246it [00:04, 55.80it/s] Epoch: 67 | b_loss: 0.3573, b_acc: 89.0625\n",
      "342it [00:06, 55.78it/s]\n",
      "\n",
      "EPOCH 67 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 68 | b_loss: 0.1786, b_acc: 96.09375\n",
      "246it [00:04, 55.78it/s] Epoch: 68 | b_loss: 0.1646, b_acc: 93.75\n",
      "342it [00:06, 55.84it/s]\n",
      "\n",
      "EPOCH 68 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 69 | b_loss: 0.1792, b_acc: 96.09375\n",
      "246it [00:04, 56.08it/s] Epoch: 69 | b_loss: 0.1449, b_acc: 96.09375\n",
      "342it [00:06, 56.02it/s]\n",
      "\n",
      "EPOCH 69 - Val acc: 81.80131904369333\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 70 | b_loss: 0.2294, b_acc: 93.75\n",
      "246it [00:04, 56.11it/s] Epoch: 70 | b_loss: 0.0735, b_acc: 98.4375\n",
      "342it [00:06, 56.11it/s]\n",
      "\n",
      "EPOCH 70 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 71 | b_loss: 0.2546, b_acc: 90.625\n",
      "246it [00:04, 55.78it/s] Epoch: 71 | b_loss: 0.1527, b_acc: 95.3125\n",
      "342it [00:06, 55.89it/s]\n",
      "\n",
      "EPOCH 71 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 72 | b_loss: 0.1121, b_acc: 95.3125\n",
      "246it [00:04, 55.81it/s] Epoch: 72 | b_loss: 0.0970, b_acc: 95.3125\n",
      "342it [00:06, 55.93it/s]\n",
      "\n",
      "EPOCH 72 - Val acc: 81.80131904369333\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 73 | b_loss: 0.4088, b_acc: 89.0625\n",
      "246it [00:04, 55.91it/s] Epoch: 73 | b_loss: 0.3011, b_acc: 89.84375\n",
      "342it [00:06, 55.91it/s]\n",
      "\n",
      "EPOCH 73 - Val acc: 81.98680956306677\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 74 | b_loss: 0.2225, b_acc: 92.96875\n",
      "246it [00:04, 56.21it/s] Epoch: 74 | b_loss: 0.0836, b_acc: 97.65625\n",
      "342it [00:06, 56.10it/s]\n",
      "\n",
      "EPOCH 74 - Val acc: 82.11046990931574\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 75 | b_loss: 0.0811, b_acc: 97.65625\n",
      "246it [00:04, 55.96it/s] Epoch: 75 | b_loss: 0.1894, b_acc: 96.09375\n",
      "342it [00:06, 55.84it/s]\n",
      "\n",
      "EPOCH 75 - Val acc: 82.00741962077494\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 76 | b_loss: 0.2070, b_acc: 93.75\n",
      "246it [00:04, 55.92it/s] Epoch: 76 | b_loss: 0.2298, b_acc: 93.75\n",
      "342it [00:06, 55.83it/s]\n",
      "\n",
      "EPOCH 76 - Val acc: 81.760098928277\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 77 | b_loss: 0.1367, b_acc: 96.875\n",
      "246it [00:04, 55.98it/s] Epoch: 77 | b_loss: 0.1831, b_acc: 93.75\n",
      "342it [00:06, 55.97it/s]\n",
      "\n",
      "EPOCH 77 - Val acc: 82.04863973619126\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 78 | b_loss: 0.2262, b_acc: 90.625\n",
      "246it [00:04, 55.80it/s] Epoch: 78 | b_loss: 0.1524, b_acc: 95.3125\n",
      "342it [00:06, 55.99it/s]\n",
      "\n",
      "EPOCH 78 - Val acc: 82.06924979389942\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 79 | b_loss: 0.0635, b_acc: 99.21875\n",
      "246it [00:04, 55.91it/s] Epoch: 79 | b_loss: 0.2070, b_acc: 92.96875\n",
      "342it [00:06, 56.02it/s]\n",
      "\n",
      "EPOCH 79 - Val acc: 81.94558944765045\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 80 | b_loss: 0.0953, b_acc: 97.65625\n",
      "246it [00:04, 56.14it/s] Epoch: 80 | b_loss: 0.1780, b_acc: 95.3125\n",
      "342it [00:06, 56.10it/s]\n",
      "\n",
      "EPOCH 80 - Val acc: 81.73948887056883\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 81 | b_loss: 0.1590, b_acc: 94.53125\n",
      "246it [00:04, 55.93it/s] Epoch: 81 | b_loss: 0.1118, b_acc: 96.09375\n",
      "342it [00:06, 55.96it/s]\n",
      "\n",
      "EPOCH 81 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 82 | b_loss: 0.1470, b_acc: 93.75\n",
      "246it [00:04, 56.04it/s] Epoch: 82 | b_loss: 0.1933, b_acc: 92.1875\n",
      "342it [00:06, 55.91it/s]\n",
      "\n",
      "EPOCH 82 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 83 | b_loss: 0.2226, b_acc: 92.96875\n",
      "246it [00:04, 56.12it/s] Epoch: 83 | b_loss: 0.1736, b_acc: 95.3125\n",
      "342it [00:06, 56.11it/s]\n",
      "\n",
      "EPOCH 83 - Val acc: 82.06924979389942\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 84 | b_loss: 0.1949, b_acc: 94.53125\n",
      "246it [00:04, 55.84it/s] Epoch: 84 | b_loss: 0.3123, b_acc: 94.53125\n",
      "342it [00:06, 55.91it/s]\n",
      "\n",
      "EPOCH 84 - Val acc: 82.11046990931574\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 85 | b_loss: 0.2599, b_acc: 90.625\n",
      "246it [00:04, 55.98it/s] Epoch: 85 | b_loss: 0.2975, b_acc: 91.40625\n",
      "342it [00:06, 56.00it/s]\n",
      "\n",
      "EPOCH 85 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 86 | b_loss: 0.2347, b_acc: 89.84375\n",
      "246it [00:04, 56.21it/s] Epoch: 86 | b_loss: 0.0674, b_acc: 96.875\n",
      "342it [00:06, 56.12it/s]\n",
      "\n",
      "EPOCH 86 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 87 | b_loss: 0.1208, b_acc: 97.65625\n",
      "246it [00:04, 55.70it/s] Epoch: 87 | b_loss: 0.1463, b_acc: 96.09375\n",
      "342it [00:06, 55.74it/s]\n",
      "\n",
      "EPOCH 87 - Val acc: 81.88375927452597\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 88 | b_loss: 0.2200, b_acc: 93.75\n",
      "246it [00:04, 56.05it/s] Epoch: 88 | b_loss: 0.0901, b_acc: 98.4375\n",
      "342it [00:06, 55.98it/s]\n",
      "\n",
      "EPOCH 88 - Val acc: 81.760098928277\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 89 | b_loss: 0.2132, b_acc: 93.75\n",
      "246it [00:04, 55.95it/s] Epoch: 89 | b_loss: 0.2107, b_acc: 95.3125\n",
      "342it [00:06, 55.97it/s]\n",
      "\n",
      "EPOCH 89 - Val acc: 82.0280296784831\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 90 | b_loss: 0.2471, b_acc: 92.96875\n",
      "246it [00:04, 55.95it/s] Epoch: 90 | b_loss: 0.1161, b_acc: 96.09375\n",
      "342it [00:06, 55.94it/s]\n",
      "\n",
      "EPOCH 90 - Val acc: 81.82192910140148\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 91 | b_loss: 0.1857, b_acc: 93.75\n",
      "246it [00:04, 55.82it/s] Epoch: 91 | b_loss: 0.2430, b_acc: 94.53125\n",
      "342it [00:06, 55.79it/s]\n",
      "\n",
      "EPOCH 91 - Val acc: 82.06924979389942\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 92 | b_loss: 0.2915, b_acc: 92.1875\n",
      "246it [00:04, 56.14it/s] Epoch: 92 | b_loss: 0.2105, b_acc: 92.96875\n",
      "342it [00:06, 56.00it/s]\n",
      "\n",
      "EPOCH 92 - Val acc: 82.0280296784831\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 93 | b_loss: 0.2089, b_acc: 92.1875\n",
      "246it [00:04, 56.07it/s] Epoch: 93 | b_loss: 0.1297, b_acc: 96.875\n",
      "342it [00:06, 55.94it/s]\n",
      "\n",
      "EPOCH 93 - Val acc: 82.1929101401484\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 94 | b_loss: 0.0922, b_acc: 96.875\n",
      "246it [00:04, 56.10it/s] Epoch: 94 | b_loss: 0.1315, b_acc: 93.75\n",
      "342it [00:06, 56.11it/s]\n",
      "\n",
      "EPOCH 94 - Val acc: 81.96619950535862\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 95 | b_loss: 0.1779, b_acc: 93.75\n",
      "246it [00:04, 56.04it/s] Epoch: 95 | b_loss: 0.1799, b_acc: 95.3125\n",
      "342it [00:06, 55.88it/s]\n",
      "\n",
      "EPOCH 95 - Val acc: 81.78070898598516\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 96 | b_loss: 0.2747, b_acc: 89.84375\n",
      "246it [00:04, 56.00it/s] Epoch: 96 | b_loss: 0.1547, b_acc: 96.09375\n",
      "342it [00:06, 55.93it/s]\n",
      "\n",
      "EPOCH 96 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 97 | b_loss: 0.1568, b_acc: 95.3125\n",
      "246it [00:04, 55.73it/s] Epoch: 97 | b_loss: 0.1533, b_acc: 96.875\n",
      "342it [00:06, 55.74it/s]\n",
      "\n",
      "EPOCH 97 - Val acc: 81.82192910140148\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 98 | b_loss: 0.1761, b_acc: 95.3125\n",
      "246it [00:04, 55.72it/s] Epoch: 98 | b_loss: 0.2431, b_acc: 92.1875\n",
      "342it [00:06, 55.78it/s]\n",
      "\n",
      "EPOCH 98 - Val acc: 81.9249793899423\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 99 | b_loss: 0.1336, b_acc: 96.09375\n",
      "246it [00:04, 55.98it/s] Epoch: 99 | b_loss: 0.2266, b_acc: 92.1875\n",
      "342it [00:06, 55.90it/s]\n",
      "\n",
      "EPOCH 99 - Val acc: 82.21352019785655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(100, fnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:20:39.031241Z",
     "start_time": "2018-08-08T17:20:39.024226Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/model.py\n",
    "# https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "# Draft implementation\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, e_size=300, k_num=100, k_sizes=[3, 4, 5]):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.dropout_e = nn.Dropout(0.2)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, k_num, (k, e_size)) for k in k_sizes])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output_l = nn.Linear(len(k_sizes)*k_num, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.e(x)  # (N, W, D)\n",
    "        x = self.dropout_e(x)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        \n",
    "        x = [self.dropout(F.relu(conv(x)).squeeze(3)) for conv in self.convs]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] \n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        return self.output_l(x)\n",
    "\n",
    "    \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:20:39.673110Z",
     "start_time": "2018-08-08T17:20:39.445947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (e): Embedding(60000, 300)\n",
      "  (dropout_e): Dropout(p=0.2)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (output_l): Linear(in_features=300, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = SimpleCNN(MAX_SIZE, MAX_VOCAB, CLASS_COUNT).cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:20:43.451298Z",
     "start_time": "2018-08-08T17:20:41.688535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:21:21.970528Z",
     "start_time": "2018-08-08T17:21:21.967025Z"
    }
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(cnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T17:57:14.163437Z",
     "start_time": "2018-08-08T17:52:31.479184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 0.1681, b_acc: 95.3125\n",
      "250it [00:13, 18.65it/s] Epoch: 0 | b_loss: 0.2765, b_acc: 92.96875\n",
      "342it [00:18, 18.65it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 92.55976916735366\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 0.1518, b_acc: 95.3125\n",
      "250it [00:13, 18.74it/s] Epoch: 1 | b_loss: 0.1871, b_acc: 92.96875\n",
      "342it [00:18, 18.77it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 92.31244847485573\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 0.3224, b_acc: 89.84375\n",
      "250it [00:13, 18.05it/s] Epoch: 2 | b_loss: 0.1485, b_acc: 96.875\n",
      "342it [00:18, 18.11it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 92.35366859027205\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 0.1194, b_acc: 96.875\n",
      "250it [00:13, 18.82it/s] Epoch: 3 | b_loss: 0.1504, b_acc: 94.53125\n",
      "342it [00:18, 18.84it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 92.45671887881286\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.3029, b_acc: 92.1875\n",
      "250it [00:13, 18.43it/s] Epoch: 4 | b_loss: 0.1258, b_acc: 96.875\n",
      "342it [00:18, 18.55it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 92.35366859027205\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.0705, b_acc: 98.4375\n",
      "250it [00:13, 18.75it/s] Epoch: 5 | b_loss: 0.1616, b_acc: 95.3125\n",
      "342it [00:18, 18.77it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 92.18878812860676\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.1627, b_acc: 93.75\n",
      "250it [00:13, 18.14it/s] Epoch: 6 | b_loss: 0.2477, b_acc: 92.1875\n",
      "342it [00:18, 18.24it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 92.25061830173125\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.1295, b_acc: 97.65625\n",
      "250it [00:13, 18.77it/s] Epoch: 7 | b_loss: 0.1607, b_acc: 94.53125\n",
      "342it [00:18, 18.78it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 92.31244847485573\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.1939, b_acc: 93.75\n",
      "250it [00:13, 18.76it/s] Epoch: 8 | b_loss: 0.2225, b_acc: 92.96875\n",
      "342it [00:18, 18.71it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 92.51854905193734\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.0859, b_acc: 96.09375\n",
      "250it [00:13, 18.68it/s] Epoch: 9 | b_loss: 0.1429, b_acc: 95.3125\n",
      "342it [00:18, 18.71it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 92.2712283594394\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.0470, b_acc: 97.65625\n",
      "250it [00:13, 18.28it/s] Epoch: 10 | b_loss: 0.1293, b_acc: 95.3125\n",
      "342it [00:18, 18.39it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 92.25061830173125\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.2037, b_acc: 93.75\n",
      "250it [00:13, 18.84it/s] Epoch: 11 | b_loss: 0.2312, b_acc: 97.65625\n",
      "342it [00:18, 18.88it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 92.23000824402308\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.0980, b_acc: 97.65625\n",
      "250it [00:13, 18.89it/s] Epoch: 12 | b_loss: 0.2915, b_acc: 94.53125\n",
      "342it [00:18, 18.87it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 92.35366859027205\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.0843, b_acc: 95.3125\n",
      "250it [00:13, 18.77it/s] Epoch: 13 | b_loss: 0.0987, b_acc: 96.875\n",
      "342it [00:18, 18.83it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 92.60098928276999\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.2594, b_acc: 92.1875\n",
      "249it [00:13, 18.87it/s] Epoch: 14 | b_loss: 0.1631, b_acc: 94.53125\n",
      "342it [00:18, 18.88it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 92.29183841714757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, cnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:15:31.973411Z",
     "start_time": "2018-08-04T00:15:31.889847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type SimpleCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, DATA_PATH/'models/cnn_es128_knum100_ksz345_90d8acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:16:22.710133Z",
     "start_time": "2018-08-06T11:16:22.705120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, e_size, bs, n_layers, n_outputs, n_hidden=128):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.n_layers, self.n_hidden, self.n_outputs = vocab_size, n_layers, n_hidden, n_outputs\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.rnn = nn.GRU(e_size, n_hidden, n_layers, dropout=0.5, batch_first=True)\n",
    "        self.l_out = nn.Linear(n_hidden, n_outputs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs.size(0)\n",
    "        hidden = self.init_hidden(bs)\n",
    "        outp, h = self.rnn(self.e(cs), hidden)\n",
    "        outp = outp[:,-1,:] # all batches, last word, all output values\n",
    "        fc_outp = self.l_out(outp)\n",
    "        return fc_outp\n",
    "        \n",
    "            \n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        return torch.zeros(self.n_layers, bs, self.n_hidden).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:16:23.149910Z",
     "start_time": "2018-08-06T11:16:22.937725Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (e): Embedding(60000, 300)\n",
      "  (rnn): GRU(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (l_out): Linear(in_features=128, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gru = GRU(MAX_VOCAB, 300, bs, 2, CLASS_COUNT).cuda()\n",
    "print(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:16:24.682549Z",
     "start_time": "2018-08-06T11:16:24.617429Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val = gru(xs.cuda())\n",
    "test_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:17:13.789111Z",
     "start_time": "2018-08-06T11:17:13.786109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(gru.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:23:49.945761Z",
     "start_time": "2018-08-06T11:17:18.697148Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 4.9856, b_acc: 0.0\n",
      "250it [00:18, 13.51it/s] Epoch: 0 | b_loss: 2.1697, b_acc: 45.3125\n",
      "342it [00:25, 13.45it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 57.04863973619126\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 1.7913, b_acc: 57.8125\n",
      "250it [00:18, 13.49it/s] Epoch: 1 | b_loss: 0.9771, b_acc: 76.5625\n",
      "342it [00:25, 13.52it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 73.3305853256389\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 0.9018, b_acc: 78.90625\n",
      "250it [00:18, 13.53it/s] Epoch: 2 | b_loss: 0.7622, b_acc: 78.90625\n",
      "342it [00:25, 13.59it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 80.87386644682606\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 0.5536, b_acc: 86.71875\n",
      "250it [00:18, 13.64it/s] Epoch: 3 | b_loss: 0.5346, b_acc: 88.28125\n",
      "342it [00:25, 13.62it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 83.38829348722176\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.3831, b_acc: 90.625\n",
      "250it [00:18, 13.27it/s] Epoch: 4 | b_loss: 0.5824, b_acc: 88.28125\n",
      "342it [00:25, 13.27it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 85.6760098928277\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.3436, b_acc: 92.96875\n",
      "250it [00:19, 13.10it/s] Epoch: 5 | b_loss: 0.2545, b_acc: 94.53125\n",
      "342it [00:25, 13.19it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 86.68590272052762\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.2083, b_acc: 94.53125\n",
      "250it [00:18, 13.55it/s] Epoch: 6 | b_loss: 0.1967, b_acc: 96.875\n",
      "342it [00:25, 13.45it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 87.30420445177246\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.2597, b_acc: 93.75\n",
      "250it [00:19, 12.81it/s] Epoch: 7 | b_loss: 0.1991, b_acc: 96.09375\n",
      "342it [00:26, 12.94it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 88.10799670239076\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.1370, b_acc: 96.875\n",
      "250it [00:18, 13.27it/s] Epoch: 8 | b_loss: 0.0928, b_acc: 98.4375\n",
      "342it [00:25, 13.40it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 88.31409727947238\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.0296, b_acc: 100.0\n",
      "250it [00:18, 13.66it/s] Epoch: 9 | b_loss: 0.0521, b_acc: 98.4375\n",
      "342it [00:25, 13.53it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 88.72629843363562\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.0412, b_acc: 99.21875\n",
      "250it [00:18, 13.41it/s] Epoch: 10 | b_loss: 0.0553, b_acc: 99.21875\n",
      "342it [00:25, 13.48it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 88.64385820280297\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.0443, b_acc: 99.21875\n",
      "250it [00:18, 13.67it/s] Epoch: 11 | b_loss: 0.0178, b_acc: 99.21875\n",
      "342it [00:24, 13.71it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 89.38582028029678\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.0240, b_acc: 100.0\n",
      "250it [00:18, 13.30it/s] Epoch: 12 | b_loss: 0.0353, b_acc: 99.21875\n",
      "342it [00:25, 13.36it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 89.24154987633965\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.0213, b_acc: 100.0\n",
      "250it [00:18, 13.35it/s] Epoch: 13 | b_loss: 0.0753, b_acc: 97.65625\n",
      "342it [00:25, 13.39it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 88.87056883759274\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.0284, b_acc: 100.0\n",
      "250it [00:18, 13.47it/s] Epoch: 14 | b_loss: 0.0291, b_acc: 99.21875\n",
      "342it [00:25, 13.48it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 88.89117889530091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, gru, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:24:14.760018Z",
     "start_time": "2018-08-06T11:24:14.754013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, e_size, bs, n_layers, n_outputs, n_hidden=128):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.n_layers, self.n_hidden, self.n_outputs = vocab_size, n_layers, n_hidden, n_outputs\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.rnn = nn.LSTM(e_size, n_hidden, n_layers, dropout=0.5, batch_first=True)\n",
    "        self.l_out = nn.Linear(n_hidden, n_outputs)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs.size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp, h = self.rnn(self.e(cs), self.h)\n",
    "        outp = outp[:,-1,:] # all batches, last word, all output values\n",
    "        #return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.n_outputs)\n",
    "        return F.log_softmax(self.l_out(outp))\n",
    "        \n",
    "            \n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "#         import pdb;pdb.set_trace()\n",
    "        self.h = (torch.zeros(self.n_layers, bs, self.n_hidden).cuda(),\n",
    "                  torch.zeros(self.n_layers, bs, self.n_hidden).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:24:15.225954Z",
     "start_time": "2018-08-06T11:24:15.041769Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (e): Embedding(60000, 256)\n",
      "  (rnn): LSTM(256, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (l_out): Linear(in_features=128, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(MAX_VOCAB, 256, bs, 2, CLASS_COUNT).cuda()\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:24:15.542687Z",
     "start_time": "2018-08-06T11:24:15.490641Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_val = lstm(xs.cuda())\n",
    "test_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:48:19.824610Z",
     "start_time": "2018-08-06T11:48:19.820598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = F.nll_loss\n",
    "opt = optim.Adam(lstm.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T11:54:59.511409Z",
     "start_time": "2018-08-06T11:48:20.268608Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 0.0247, b_acc: 99.21875\n",
      "250it [00:19, 13.06it/s] Epoch: 0 | b_loss: 0.0106, b_acc: 100.0\n",
      "342it [00:25, 13.17it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 89.98351195383347\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 0.0216, b_acc: 99.21875\n",
      "250it [00:18, 13.23it/s] Epoch: 1 | b_loss: 0.0930, b_acc: 98.4375\n",
      "342it [00:25, 13.21it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 90.04534212695796\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 0.0042, b_acc: 100.0\n",
      "250it [00:18, 13.30it/s] Epoch: 2 | b_loss: 0.0054, b_acc: 100.0\n",
      "342it [00:25, 13.30it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 90.14839241549876\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 0.0228, b_acc: 99.21875\n",
      "250it [00:19, 12.87it/s] Epoch: 3 | b_loss: 0.0361, b_acc: 99.21875\n",
      "342it [00:26, 12.94it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 90.12778235779061\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.0350, b_acc: 99.21875\n",
      "250it [00:19, 12.94it/s] Epoch: 4 | b_loss: 0.0464, b_acc: 98.4375\n",
      "342it [00:26, 13.06it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 90.14839241549876\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.0266, b_acc: 99.21875\n",
      "250it [00:18, 13.25it/s] Epoch: 5 | b_loss: 0.0145, b_acc: 100.0\n",
      "342it [00:26, 13.09it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 90.10717230008244\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.0148, b_acc: 100.0\n",
      "250it [00:19, 12.96it/s] Epoch: 6 | b_loss: 0.0051, b_acc: 100.0\n",
      "342it [00:26, 12.92it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 90.18961253091508\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.0101, b_acc: 100.0\n",
      "250it [00:18, 13.43it/s] Epoch: 7 | b_loss: 0.0173, b_acc: 100.0\n",
      "342it [00:25, 13.42it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 90.18961253091508\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.0094, b_acc: 100.0\n",
      "250it [00:19, 13.14it/s] Epoch: 8 | b_loss: 0.0174, b_acc: 100.0\n",
      "342it [00:26, 13.13it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 90.23083264633141\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.0038, b_acc: 100.0\n",
      "250it [00:19, 13.11it/s] Epoch: 9 | b_loss: 0.0424, b_acc: 99.21875\n",
      "342it [00:25, 13.17it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 90.25144270403958\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.0068, b_acc: 100.0\n",
      "250it [00:18, 13.18it/s] Epoch: 10 | b_loss: 0.0032, b_acc: 100.0\n",
      "342it [00:25, 13.21it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 90.27205276174773\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.0107, b_acc: 99.21875\n",
      "250it [00:18, 13.25it/s] Epoch: 11 | b_loss: 0.0167, b_acc: 100.0\n",
      "342it [00:25, 13.24it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 90.33388293487222\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.0114, b_acc: 99.21875\n",
      "250it [00:19, 13.13it/s] Epoch: 12 | b_loss: 0.0030, b_acc: 100.0\n",
      "342it [00:26, 13.10it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 90.35449299258038\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.0039, b_acc: 100.0\n",
      "250it [00:19, 12.96it/s] Epoch: 13 | b_loss: 0.0056, b_acc: 100.0\n",
      "342it [00:26, 13.01it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 90.18961253091508\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.0179, b_acc: 99.21875\n",
      "250it [00:18, 13.23it/s] Epoch: 14 | b_loss: 0.0146, b_acc: 100.0\n",
      "342it [00:25, 13.27it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 90.14839241549876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, lstm, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:49:48.600967Z",
     "start_time": "2018-08-01T18:49:48.598965Z"
    }
   },
   "source": [
    "##### Implementation\n",
    "- Disable dropout during test time (proper eval)+\n",
    "- Try a properly tuned model\n",
    "    - cnn seems to get 92.47% acc, high variance (overfitting) on training data\n",
    "        - e_size=300, bs=128, lr=1e-3 got same acc in 6 epochs opposed to ~40\n",
    "    + might need a bigger batch size+\n",
    "    + try more regularization\n",
    "- Try learning rate finder\n",
    "- Learning rate cosine annealing\n",
    "- SGD with restarts\n",
    "- Try to predict multiple labels\n",
    "\n",
    "##### Analysis\n",
    "+ Can also check how balanced the classes are+\n",
    "    - Rework unbalanced classes or set class weights\n",
    "+ Try a simple shallow learning model+\n",
    "    - 94.5% accuracy, without fiddling with hyperparams and models much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Shallow SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:51:22.772369Z",
     "start_time": "2018-08-02T20:51:22.730846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-5, random_state=42,\n",
    "                                           max_iter=25, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.107962Z",
     "start_time": "2018-08-02T20:51:23.108451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_clf.fit(train_texts, train_labels)  \n",
    "predicted = text_clf.predict(val_texts)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.115468Z",
     "start_time": "2018-08-02T20:55:00.109964Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453833470733718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == np.asarray(val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "43px",
    "left": "1548px",
    "right": "20px",
    "top": "118px",
    "width": "302px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
