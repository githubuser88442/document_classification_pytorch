{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.032211Z",
     "start_time": "2018-08-05T15:23:57.819453Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.036215Z",
     "start_time": "2018-08-05T15:24:00.033212Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('DATA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset properties, inspection, tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.508586Z",
     "start_time": "2018-08-05T15:24:00.038217Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'x_and_y_cleaned.pkl'\n",
    "with open(DATA_PATH/DATASET_NAME, 'rb') as f:\n",
    "    articles, categories = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.515591Z",
     "start_time": "2018-08-05T15:24:00.509586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label None as 'none'\n",
    "categories = ['none' if not x else x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.538608Z",
     "start_time": "2018-08-05T15:24:00.518594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48514\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "CLASSES = sorted(list(set(categories)))\n",
    "ARTICLE_COUNT = len(articles)\n",
    "CLASS_COUNT = len(CLASSES)\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "MAX_SIZE = 250\n",
    "\n",
    "max_vocab = 60000\n",
    "min_freq = 5\n",
    "\n",
    "print(ARTICLE_COUNT)\n",
    "print(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.557621Z",
     "start_time": "2018-08-05T15:24:00.539608Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uudised/eesti', 16451),\n",
       " ('melu/elu', 5883),\n",
       " ('uudised/maailm', 4285),\n",
       " ('uudised/krimi', 2211),\n",
       " ('televeeb/tvuudised', 1462),\n",
       " ('arvamus/kommentaar', 1342),\n",
       " ('naine/naised', 1163),\n",
       " ('naine/suhted', 1155),\n",
       " ('melu/seltskond', 969),\n",
       " ('sport/jalgpall', 885),\n",
       " ('naine/ilu', 817),\n",
       " ('uudised/kiiksud', 544),\n",
       " ('sport/korvpall', 541),\n",
       " ('tervis/keha', 502),\n",
       " ('blogid/londonilustiblogi', 480),\n",
       " ('uudised/ilm', 461),\n",
       " ('arvamus/juhtkiri', 454),\n",
       " ('sport/varia', 413),\n",
       " ('raha/kodu', 353),\n",
       " ('meedia/galeriid', 334),\n",
       " ('arvamus/repliik', 324),\n",
       " ('melu/saund', 323),\n",
       " ('melu/sunagukolab', 322),\n",
       " ('sport/kergejoustik', 316),\n",
       " ('meedia/videod', 315)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class balance check:\n",
    "freq = Counter(o for o in categories)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.568629Z",
     "start_time": "2018-08-05T15:24:00.559622Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiaeri', 'arvamus', 'arvamus/intervjuu', 'arvamus/juhtkiri', 'arvamus/karikatuur', 'arvamus/kommentaar', 'arvamus/koomiks', 'arvamus/lugejakiri', 'arvamus/nadalatipud', 'arvamus/repliik', 'arvamus/seisukoht', 'blogid/avastaeestimaad', 'blogid/aveameerikas', 'blogid/filmiblogi', 'blogid/hollandiblogi', 'blogid/indoneesiablogi', 'blogid/jumestusblogi', 'blogid/korvpallimm', 'blogid/lehesaba', 'blogid/londonilustiblogi', 'blogid/malluka', 'blogid/meistriteblogi', 'blogid/moeajakiri', 'blogid/moekeeris', 'blogid/motteid', 'blogid/muusikablogi', 'blogid/opetajablogi', 'blogid/psyhholoogiablogi', 'blogid/pulmablogi', 'blogid/raamatublogi', 'blogid/raha', 'blogid/seljakotigablogi', 'blogid/spordiblogi', 'blogid/teleblogi', 'blogid/trenniblogi', 'blogid/valdojahilo', 'blogid/yksikvanem', 'eestinaine/elud-inimesed', 'eriline/horoskoop', 'eriline/mystika', 'joulud', 'kroonika/eesti', 'lemmikloom', 'linnaleht/arvamus', 'linnaleht/dilaila', 'linnaleht/karikatuur', 'linnaleht/kodusedlood', 'linnaleht/paevateema', 'linnaleht/parnu', 'linnaleht/persoon', 'linnaleht/sport', 'linnaleht/tallinn', 'linnaleht/tarbija', 'linnaleht/tartu', 'linnaleht/toimetajaveerg', 'linnaleht/vabaaeg', 'meedia', 'meedia/galeriid', 'meedia/videod', 'mees/auto', 'mehele/reis', 'mehele/tehnika', 'melu/eestitop', 'melu/elu', 'melu/eurovision', 'melu/film', 'melu/saund', 'melu/saund/noorteband', 'melu/saund/noorteband/galeriid', 'melu/saund/noorteband/osalejad', 'melu/seltskond', 'melu/sunagukolab', 'naile/ilu', 'naine', 'naine/ilu', 'naine/naised', 'naine/stella', 'naine/suhted', 'naine/toit', 'none', 'oltv/ilukool', 'oltv/sporttv', 'oltv/uudistv', 'pokker', 'raha', 'raha/kodu', 'raha/rahakott', 'raha/tarbija', 'raha/tehnika', 'sport', 'sport/automoto', 'sport/doping', 'sport/hoki', 'sport/jalgpall', 'sport/jalgrattasport', 'sport/kasipall', 'sport/kergejoustik', 'sport/korvpall', 'sport/korvpallimm', 'sport/maadlus', 'sport/meistriteliiga', 'sport/mm2014', 'sport/muu', 'sport/nba', 'sport/nfl', 'sport/olympia', 'sport/soudmine', 'sport/talisport', 'sport/tantsutydrukud', 'sport/tennis', 'sport/ujumine', 'sport/varia', 'sport/vehklemine', 'sport/vorkpall', 'sport/vormel', 'televeeb/tvuudised', 'tervis', 'tervis/eakad', 'tervis/heanou', 'tervis/hygieen', 'tervis/keha', 'tervis/kysimus', 'tervis/lapsed', 'tervis/meeled', 'tervis/raamat', 'tervis/rasedus', 'tervis/toitumine', 'tervis/treenimine', 'tervis/uudised', 'uudised', 'uudised/eesti', 'uudised/ilm', 'uudised/kiiksud', 'uudised/krimi', 'uudised/maailm', 'uudised/ol70', 'uudised/presidendiball', 'uudised/valimised']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:00.584644Z",
     "start_time": "2018-08-05T15:24:00.570631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE:  Kas parima aastavahetuse programmi pani eetrisse ETV, Kanal 2 või hoopis TV3? ETVst näegid vaatajad saateid \"V ...\n",
      "CATEGORY:  televeeb/tvuudised\n"
     ]
    }
   ],
   "source": [
    "# Dataset examples:\n",
    "index = 0\n",
    "print('ARTICLE: ', articles[index][0:110], '...')\n",
    "print('CATEGORY: ', categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T21:18:44.131826Z",
     "start_time": "2018-07-29T21:18:41.169277Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.0\n",
      "387.0457805994146\n"
     ]
    }
   ],
   "source": [
    "# Get median/average word count\n",
    "print(np.median([len(x.split(' ')) for x in articles]))\n",
    "print(np.mean([len(x.split(' ')) for x in articles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:33.989982Z",
     "start_time": "2018-07-31T12:20:33.893399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# labels = []\n",
    "# for x in categories:\n",
    "#     y = [0 for x in range(CLASS_COUNT)]\n",
    "#     y[CLASSES.index(x)] = 1\n",
    "#     labels.append(y)\n",
    "\n",
    "# Class index encoding\n",
    "labels = []\n",
    "for x in categories:\n",
    "    y = CLASSES.index(x)\n",
    "    labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:20:55.175534Z",
     "start_time": "2018-07-31T12:20:54.333043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(articles, labels, test_size=0.1, random_state=42)\n",
    "pickle.dump([train_texts, val_texts, train_labels, val_labels], open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:01.369147Z",
     "start_time": "2018-07-30T13:19:35.308770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tok_train = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(train_texts))\n",
    "tok_val = Tokenizer(lang='xx').proc_all_mp(partition_by_cores(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:18.105637Z",
     "start_time": "2018-07-30T13:25:14.806690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 657926),\n",
       " ('.', 559252),\n",
       " ('\"', 217175),\n",
       " ('ja', 210514),\n",
       " ('on', 197759),\n",
       " ('et', 150766),\n",
       " ('ei', 106727),\n",
       " ('kui', 74991),\n",
       " ('ta', 66639),\n",
       " ('ka', 58212),\n",
       " ('oli', 51101),\n",
       " ('oma', 46727),\n",
       " ('-', 46020),\n",
       " ('ning', 45314),\n",
       " ('see', 45285),\n",
       " ('xbos', 43662),\n",
       " ('xfld', 43662),\n",
       " ('0', 42597),\n",
       " ('aga', 38936),\n",
       " ('t_up', 31812),\n",
       " ('mis', 31436),\n",
       " ('ma', 30478),\n",
       " ('siis', 29830),\n",
       " ('kes', 29218),\n",
       " ('tema', 28739)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_train for p in o)\n",
    "print(len(tok_train))\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:32.945314Z",
     "start_time": "2018-07-30T13:25:32.940310Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xbos', 'vehklemisliidu', 'president', ',', 'riigikogu', 'liige', 'margus', 'hanson', 'tõdes', ',', 'et', 'naiskond', 'vehkles', 'kaunilt', 'kuni', 'finaalini', '.', '\"', 'naised', 'olid', 'väga', 'tublid', '.', 'meil', 'on', 'noor', ',', 'perspektiivikas', 'ja', 'arenev', 'võistkond', ':', 'teise', 'kohaga', 'tuleb', 'igati', 'rahul', 'olla', ',', 'sest', 'ega', 'jõu', 'ja', 'võimu', 'vastu', 'ei', 'saa', '!', '\"', 'hanson', 'lisas', ',', 'et', 'teda', 'rõõmustab', 'sten', 'priinitsa', 'individuaalturniiril', 'saadud', 'kaheksas', 'koht', ',', 'millega', 'mees', 'suurendab', 'ka', 't_up', 'eok', 'toetusraha', '.', '\"', 'meie', 'vehklejad', 'on', 'tõestanud', ',', 'et', 'neid', 'saab', 'usaldada', '.', 'sportlased', 'seavad', 'kõrged', 'sihid', 'ja', 'on', 'võimelised', 'neid', 'täitma', ';', '\"', 'kinnitas', 'ta', '.', 'ühtlasi', 'märkis', 'hanson', ',', 'et', 'suur', 'on', 'treener', 'igor', 'tšikinjovi', 'panus', '.', '\"', 'ta', 'on', 'toonud', 'värsket', 'verd', 'ja', 'hingamist', '.', 'see', 'on', 'hästi', 'mõjunud', '.', '\"', 'xfld', 'tk_wrep', '151', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:25:48.253589Z",
     "start_time": "2018-07-30T13:25:47.768744Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 72534),\n",
       " ('.', 62293),\n",
       " ('\"', 23741),\n",
       " ('ja', 23599),\n",
       " ('on', 21847),\n",
       " ('et', 16600),\n",
       " ('ei', 11625),\n",
       " ('kui', 8402),\n",
       " ('ta', 7294),\n",
       " ('ka', 6594),\n",
       " ('oli', 5541),\n",
       " ('ning', 5219),\n",
       " ('oma', 5142),\n",
       " ('-', 5101),\n",
       " ('see', 4893),\n",
       " ('xbos', 4852),\n",
       " ('xfld', 4852),\n",
       " ('0', 4743),\n",
       " ('aga', 4345),\n",
       " ('mis', 3589),\n",
       " ('t_up', 3475),\n",
       " ('ma', 3323),\n",
       " ('tema', 3264),\n",
       " ('eesti', 3248),\n",
       " ('siis', 3235)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_val = Counter(p for o in tok_val for p in o)\n",
    "print(len(tok_val))\n",
    "freq_val.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:09.459592Z",
     "start_time": "2018-07-30T13:26:04.771503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens/tok_train_pad.npy', tok_train)\n",
    "np.save(DATA_PATH/'tokens/tok_val_pad.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:24.815144Z",
     "start_time": "2018-07-30T13:26:24.558458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:26:40.051470Z",
     "start_time": "2018-07-30T13:26:40.007939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:43:10.741270Z",
     "start_time": "2018-07-30T13:43:06.742874Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_lm = np.array([[stoi[o] for o in p] for p in tok_train])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:01.204885Z",
     "start_time": "2018-07-30T13:52:00.857137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pad and crop values\n",
    "train_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in train_lm]\n",
    "val_lm_pad = [x[:MAX_SIZE] if len(x) > MAX_SIZE else x + [0 for i in range(MAX_SIZE - len(x))] for x in val_lm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:52:28.419054Z",
     "start_time": "2018-07-30T13:52:27.621530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'tokens'/'trn_ids.npy', train_lm_pad) # Oversaved all as padded\n",
    "np.save(DATA_PATH/'tokens'/'val_ids.npy', val_lm_pad)\n",
    "pickle.dump(itos, open(DATA_PATH/'tokens'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:08.195443Z",
     "start_time": "2018-08-05T15:24:07.747006Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = pickle.load(open(DATA_PATH/'tokens'/'trnx_valx_trny_valy_ind_split.pkl', 'rb'))\n",
    "train_lm = np.load(DATA_PATH/'tokens'/'trn_ids.npy')\n",
    "val_lm = np.load(DATA_PATH/'tokens'/'val_ids.npy')\n",
    "itos = pickle.load(open(DATA_PATH/'tokens'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:41:06.002194Z",
     "start_time": "2018-07-30T13:41:05.996690Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos Peaminister Taavi Rõivas jätab võimutüli tõttu ära visiidid Leedusse ja Rootsi, teda asendab väliskaubandus- ja ettevõtlusminister Anne Sulling.  Valitsuse pressiesindaja kinnitas pühapäeva pärastlõunal, et Rõivas ei sõida esmaspäeval visiidile Leetu ja Rootsi. Pressiesindaja teatel jäävad visiidid ära \"seoses ametikohustustega Eestis\". Reformierakonna esimees, peaminister Taavi Rõivas pidi esmaspäeval koos teiste Balti riikide valitsusjuhtidega osalema Leedus Klaipedas aset leidval LNG ujuvterminali saabumistseremoonial. Enne tseremooniat pidi aset leidma peaministrite ning Ameerika Ühendriikide esindajate ühine töölõuna. Pärastlõunal pidi Rõivas suunduma edasi Stockholmi, kus toimub Balti- ja Põhjamaade tippkohtumine. Rootsi, Soome, Norra, Islandi, Taani, Eesti, Läti ja Leedu peaministrite kohtumisel räägitakse majanduse olukorrast Euroopas, transatlantilistest suhetest ning Ukrainaga seotud arengutest. Pühapäeval kohtuvad Reformierakonna ja Sotsiaaldemokraatliku Erakonna esimehed, et arutada rahandusminister Jürgen Ligi väljaütlemisest puhkenud tüli. xfld 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:46:21.018841Z",
     "start_time": "2018-07-30T13:46:21.015339Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 425, 524, 658, 2109, 0, 254, 63, 48013, 0, 5, 563, 2, 84, 28902, 0, 5, 53171, 1428, 26646, 3, 64, 755, 588, 438, 2029, 1368, 2, 7, 658, 8, 7061, 661, 4845, 17602, 5, 563, 3, 588, 704, 1070, 48013, 63, 4, 552, 0, 136, 4, 3, 813, 829, 2, 425, 524, 658, 388, 661, 79, 383, 555, 1197, 0, 3403, 5258, 0, 1815, 0, 21, 11591, 0, 0, 3, 105, 50278, 388, 1815, 3905, 31416, 15, 542, 1406, 7017, 3196, 0, 3, 1368, 388, 658, 0, 180, 3805, 2, 45, 638, 50279, 5, 9650, 11347, 3, 563, 2, 322, 2, 954, 2, 5409, 2, 2147, 2, 27, 2, 662, 5, 1109, 31416, 2357, 2275, 3893, 3806, 938, 2, 0, 5920, 15, 12824, 433, 43618, 3, 679, 10646, 813, 5, 7930, 871, 48014, 2, 7, 3819, 1726, 1064, 194, 0, 7214, 1899, 3, 18, 37, 7215, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:21:46.538046Z",
     "start_time": "2018-07-31T12:21:46.534044Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "uudised/eesti\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])\n",
    "print(CLASSES[train_labels[0]])\n",
    "# print(CLASSES[train_labels[0].index(1)]) # for one hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:08.737851Z",
     "start_time": "2018-08-05T15:24:08.675289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([43662, 250])\n",
      "y shape torch.Size([43662])\n",
      "x shape torch.Size([4852, 250])\n",
      "y shape torch.Size([4852])\n"
     ]
    }
   ],
   "source": [
    "bs=128\n",
    "\n",
    "class TokDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x; self.y = y\n",
    "        self.len = len(self.x)\n",
    "        self.x_data = torch.from_numpy(self.x); self.x_data = self.x_data.long()\n",
    "        self.y_data = torch.from_numpy(self.y); self.y_data = self.y_data.long()\n",
    "        print('x shape', self.x_data.shape)\n",
    "        print('y shape', self.y_data.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "ds = TokDataset(train_lm, np.asarray(train_labels))\n",
    "ds_val = TokDataset(val_lm, np.asarray(val_labels))\n",
    "dl = torch.utils.data.DataLoader(dataset=ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "dl_val = torch.utils.data.DataLoader(dataset=ds_val, batch_size=bs, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:10.829913Z",
     "start_time": "2018-08-05T15:24:10.826912Z"
    }
   },
   "outputs": [],
   "source": [
    "test_values = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:11.016727Z",
     "start_time": "2018-08-05T15:24:11.011133Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = next(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:11.662753Z",
     "start_time": "2018-08-05T15:24:11.658750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   17, 11407, 10604,  ...,     0,     0,     0],\n",
      "        [   17, 12445,  1979,  ...,     0,     0,     0],\n",
      "        [   17,     4, 35948,  ...,   362,     0,     0],\n",
      "        ...,\n",
      "        [   17,   176,   807,  ...,    59,     0,     0],\n",
      "        [   17,     4,  3036,  ...,  5367,     0,     0],\n",
      "        [   17,   526,    92,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feed-forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T12:22:09.018109Z",
     "start_time": "2018-07-31T12:22:09.013614Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:21.938615Z",
     "start_time": "2018-07-31T15:45:21.929599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, num_l, neurons: List[int], e_size=200):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.input_l = nn.Linear(e_size * input_size, neurons[0])\n",
    "        self.middle_l = nn.ModuleList()\n",
    "        for i in range(num_l):\n",
    "            self.middle_l.append(nn.Linear(neurons[i], neurons[i+1]))\n",
    "        self.output_l = nn.Linear(neurons[-1], num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        i_sz = x.shape[-1]\n",
    "        x = F.relu(self.e(x))\n",
    "        x = x.view(-1,  i_sz * x.shape[-1])\n",
    "        x = F.relu(self.input_l(x))\n",
    "        for l in self.middle_l:\n",
    "            x = F.relu(l(x))\n",
    "        return self.output_l(x) # No softmax for crossentropy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:25.090219Z",
     "start_time": "2018-07-31T15:45:24.863507Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFNN(\n",
      "  (e): Embedding(60000, 200)\n",
      "  (input_l): Linear(in_features=50000, out_features=200, bias=True)\n",
      "  (middle_l): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (1): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  )\n",
      "  (output_l): Linear(in_features=20, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = SimpleFNN(MAX_SIZE, max_vocab, CLASS_COUNT, 4, [200, 300, 100, 50, 20]).cuda()\n",
    "print(fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T15:45:29.340912Z",
     "start_time": "2018-07-31T15:45:29.335418Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 138])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pass through\n",
    "fnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T14:01:47.590476Z",
     "start_time": "2018-08-01T14:01:47.574966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(fnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:24:12.457536Z",
     "start_time": "2018-08-05T15:24:12.450533Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_dl, val_dl, crit, opt, verb=250):\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for i, data in tqdm(enumerate(train_dl)):\n",
    "            x, y = data\n",
    "            x = x.cuda(); y = y.cuda()\n",
    "\n",
    "            y_h = model(x)\n",
    "            loss = crit(y_h, y)\n",
    "            \n",
    "            # For accuracy\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y.size(0)\n",
    "            correct += (torch.argmax(y_h, 1) == y).sum().item()\n",
    "\n",
    "            if i % verb == 0:\n",
    "                print(f' Epoch: {ep} | b_loss: {loss.item():.{4}f}, b_acc: {100 * correct / total}')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Validate\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        for i, data_val in enumerate(val_dl):\n",
    "            x_val, y_val = data_val\n",
    "            x_val = x_val.cuda(); y_val = y_val.cuda()\n",
    "            \n",
    "            # .eval() doesn't turn off gradient tracking\n",
    "            with torch.no_grad():\n",
    "                y_h_val = model(x_val)\n",
    "                val_correct += (torch.argmax(y_h_val, 1) == y_val).sum().item()\n",
    "        print(f'\\nEPOCH {ep} - Val acc: {100 * val_correct / len(val_dl.dataset)}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T13:56:03.627745Z",
     "start_time": "2018-08-04T13:56:03.621751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/model.py\n",
    "# https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "# Draft implementation\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, num_outputs, e_size=300, k_num=100, k_sizes=[3, 4, 5]):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.dropout_e = nn.Dropout(0.3)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, k_num, (k, e_size)) for k in k_sizes])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output_l = nn.Linear(len(k_sizes)*k_num, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.e(x)  # (N, W, D)\n",
    "        x = self.dropout_e(x)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] \n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        \n",
    "        return self.output_l(x)\n",
    "\n",
    "    \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T13:56:05.405694Z",
     "start_time": "2018-08-04T13:56:05.204513Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (e): Embedding(60000, 300)\n",
      "  (dropout_e): Dropout(p=0.3)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (output_l): Linear(in_features=300, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = SimpleCNN(MAX_SIZE, max_vocab, CLASS_COUNT).cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T13:56:10.011256Z",
     "start_time": "2018-08-04T13:56:10.004251Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T13:56:15.968388Z",
     "start_time": "2018-08-04T13:56:15.964385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(cnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T14:00:31.403500Z",
     "start_time": "2018-08-04T13:56:17.397416Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 6.4499, b_acc: 0.0\n",
      "250it [00:11, 21.01it/s] Epoch: 0 | b_loss: 2.2496, b_acc: 48.4375\n",
      "342it [00:16, 21.05it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 66.32316570486397\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 1.9087, b_acc: 57.8125\n",
      "250it [00:12, 20.78it/s] Epoch: 1 | b_loss: 1.6934, b_acc: 61.71875\n",
      "342it [00:16, 20.64it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 76.95795548227535\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 1.5263, b_acc: 66.40625\n",
      "249it [00:12, 20.14it/s] Epoch: 2 | b_loss: 1.0044, b_acc: 75.78125\n",
      "342it [00:16, 20.12it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 82.46084089035449\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 1.0977, b_acc: 74.21875\n",
      "250it [00:12, 20.62it/s] Epoch: 3 | b_loss: 0.6896, b_acc: 85.15625\n",
      "342it [00:16, 20.80it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 85.6760098928277\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 0.6964, b_acc: 81.25\n",
      "249it [00:12, 20.74it/s] Epoch: 4 | b_loss: 1.0089, b_acc: 78.125\n",
      "342it [00:16, 20.70it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 87.92250618301732\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 0.6816, b_acc: 83.59375\n",
      "250it [00:12, 20.67it/s] Epoch: 5 | b_loss: 0.6029, b_acc: 82.8125\n",
      "342it [00:16, 20.68it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 89.77741137675186\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 0.4997, b_acc: 81.25\n",
      "249it [00:11, 21.03it/s] Epoch: 6 | b_loss: 0.4672, b_acc: 88.28125\n",
      "342it [00:16, 21.08it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 90.7254740313273\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 0.4936, b_acc: 84.375\n",
      "249it [00:11, 20.94it/s] Epoch: 7 | b_loss: 0.4142, b_acc: 89.84375\n",
      "342it [00:16, 20.94it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 91.50865622423743\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 0.3528, b_acc: 91.40625\n",
      "249it [00:11, 20.96it/s] Epoch: 8 | b_loss: 0.3653, b_acc: 92.96875\n",
      "342it [00:16, 21.05it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 91.79719703215169\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 0.3755, b_acc: 86.71875\n",
      "249it [00:11, 21.02it/s] Epoch: 9 | b_loss: 0.3605, b_acc: 91.40625\n",
      "342it [00:16, 21.08it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 91.81780708985985\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 0.1625, b_acc: 95.3125\n",
      "248it [00:11, 20.88it/s] Epoch: 10 | b_loss: 0.3409, b_acc: 92.1875\n",
      "342it [00:16, 20.95it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 92.0032976092333\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 0.1831, b_acc: 95.3125\n",
      "249it [00:11, 20.91it/s] Epoch: 11 | b_loss: 0.1612, b_acc: 96.09375\n",
      "342it [00:16, 20.98it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 92.3330585325639\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 0.3651, b_acc: 92.96875\n",
      "250it [00:12, 20.72it/s] Epoch: 12 | b_loss: 0.3677, b_acc: 92.1875\n",
      "342it [00:16, 20.62it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 92.31244847485573\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 0.2168, b_acc: 93.75\n",
      "249it [00:12, 20.44it/s] Epoch: 13 | b_loss: 0.2089, b_acc: 93.75\n",
      "342it [00:16, 20.36it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 92.72464962901896\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 0.1619, b_acc: 94.53125\n",
      "250it [00:12, 20.62it/s] Epoch: 14 | b_loss: 0.1759, b_acc: 95.3125\n",
      "342it [00:16, 20.71it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 92.58037922506183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, cnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T00:15:31.973411Z",
     "start_time": "2018-08-04T00:15:31.889847Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type SimpleCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, DATA_PATH/'models/cnn_es128_knum100_ksz345_90d8acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:55:46.395819Z",
     "start_time": "2018-08-05T15:55:46.390815Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, e_size, bs, n_layers, n_outputs, n_hidden=128):\n",
    "        super().__init__()\n",
    "        self.vocab_size, self.n_layers, self.n_hidden, self.n_outputs = vocab_size, n_layers, n_hidden, n_outputs\n",
    "        self.e = nn.Embedding(vocab_size, e_size)\n",
    "        self.rnn = nn.LSTM(e_size, n_hidden, n_layers, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, n_outputs)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        outp = outp[:,-1,:] # all batches, last word, all output values\n",
    "        #self.h = repackage_var(h)\n",
    "        #return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.n_outputs)\n",
    "        return self.l_out(outp)\n",
    "            \n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.n_layers, bs, self.n_hidden)),\n",
    "                  V(torch.zeros(self.n_layers, bs, self.n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:55:46.794676Z",
     "start_time": "2018-08-05T15:55:46.582015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (e): Embedding(60000, 300)\n",
      "  (rnn): LSTM(300, 128, num_layers=2, dropout=0.5)\n",
      "  (l_out): Linear(in_features=128, out_features=138, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = LSTM(max_vocab, 300, bs, 2, CLASS_COUNT).cuda()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:55:50.555111Z",
     "start_time": "2018-08-05T15:55:50.509075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 138])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(xs.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T15:55:51.001230Z",
     "start_time": "2018-08-05T15:55:50.998227Z"
    }
   },
   "outputs": [],
   "source": [
    "#crit = F.nll_loss\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(rnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-05T16:00:49.524276Z",
     "start_time": "2018-08-05T15:55:51.593164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s] Epoch: 0 | b_loss: 4.9263, b_acc: 0.0\n",
      "250it [00:14, 17.30it/s] Epoch: 0 | b_loss: 2.8786, b_acc: 32.03125\n",
      "342it [00:19, 17.41it/s]\n",
      "\n",
      "EPOCH 0 - Val acc: 32.8318219291014\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 1 | b_loss: 2.9183, b_acc: 36.71875\n",
      "250it [00:14, 17.52it/s] Epoch: 1 | b_loss: 3.1635, b_acc: 26.5625\n",
      "342it [00:19, 17.57it/s]\n",
      "\n",
      "EPOCH 1 - Val acc: 32.8318219291014\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 2 | b_loss: 2.8324, b_acc: 34.375\n",
      "250it [00:14, 17.75it/s] Epoch: 2 | b_loss: 2.8677, b_acc: 37.5\n",
      "342it [00:19, 17.78it/s]\n",
      "\n",
      "EPOCH 2 - Val acc: 32.8318219291014\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 3 | b_loss: 3.0707, b_acc: 32.8125\n",
      "250it [00:14, 17.55it/s] Epoch: 3 | b_loss: 3.1012, b_acc: 29.6875\n",
      "342it [00:19, 17.58it/s]\n",
      "\n",
      "EPOCH 3 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 4 | b_loss: 2.7873, b_acc: 37.5\n",
      "250it [00:14, 17.58it/s] Epoch: 4 | b_loss: 2.8920, b_acc: 36.71875\n",
      "342it [00:19, 17.60it/s]\n",
      "\n",
      "EPOCH 4 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 5 | b_loss: 2.9444, b_acc: 29.6875\n",
      "250it [00:14, 17.69it/s] Epoch: 5 | b_loss: 2.7684, b_acc: 41.40625\n",
      "342it [00:19, 17.72it/s]\n",
      "\n",
      "EPOCH 5 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 6 | b_loss: 3.1775, b_acc: 29.6875\n",
      "250it [00:14, 17.51it/s] Epoch: 6 | b_loss: 2.9426, b_acc: 34.375\n",
      "342it [00:19, 17.50it/s]\n",
      "\n",
      "EPOCH 6 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 7 | b_loss: 2.9404, b_acc: 35.15625\n",
      "250it [00:14, 17.45it/s] Epoch: 7 | b_loss: 3.0199, b_acc: 32.8125\n",
      "342it [00:19, 17.51it/s]\n",
      "\n",
      "EPOCH 7 - Val acc: 32.8318219291014\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 8 | b_loss: 2.9161, b_acc: 32.03125\n",
      "250it [00:14, 17.58it/s] Epoch: 8 | b_loss: 2.8731, b_acc: 35.15625\n",
      "342it [00:19, 17.62it/s]\n",
      "\n",
      "EPOCH 8 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 9 | b_loss: 3.0786, b_acc: 28.90625\n",
      "250it [00:14, 17.75it/s] Epoch: 9 | b_loss: 2.9323, b_acc: 30.46875\n",
      "342it [00:19, 17.77it/s]\n",
      "\n",
      "EPOCH 9 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 10 | b_loss: 2.9345, b_acc: 35.15625\n",
      "250it [00:14, 17.55it/s] Epoch: 10 | b_loss: 3.3953, b_acc: 29.6875\n",
      "342it [00:19, 17.58it/s]\n",
      "\n",
      "EPOCH 10 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 11 | b_loss: 3.0393, b_acc: 29.6875\n",
      "250it [00:14, 17.60it/s] Epoch: 11 | b_loss: 2.8709, b_acc: 38.28125\n",
      "342it [00:19, 17.62it/s]\n",
      "\n",
      "EPOCH 11 - Val acc: 32.8318219291014\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 12 | b_loss: 2.8674, b_acc: 38.28125\n",
      "250it [00:14, 17.70it/s] Epoch: 12 | b_loss: 2.9095, b_acc: 28.90625\n",
      "342it [00:19, 17.73it/s]\n",
      "\n",
      "EPOCH 12 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 13 | b_loss: 2.8562, b_acc: 32.8125\n",
      "250it [00:14, 17.54it/s] Epoch: 13 | b_loss: 2.9491, b_acc: 31.25\n",
      "342it [00:19, 17.57it/s]\n",
      "\n",
      "EPOCH 13 - Val acc: 32.81121187139324\n",
      "\n",
      "0it [00:00, ?it/s] Epoch: 14 | b_loss: 3.1481, b_acc: 28.125\n",
      "250it [00:14, 17.56it/s] Epoch: 14 | b_loss: 2.8735, b_acc: 32.03125\n",
      "342it [00:19, 17.60it/s]\n",
      "\n",
      "EPOCH 14 - Val acc: 32.81121187139324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(15, rnn, dl, dl_val, crit, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T18:49:48.600967Z",
     "start_time": "2018-08-01T18:49:48.598965Z"
    }
   },
   "source": [
    "##### Implementation\n",
    "- Disable dropout during test time (proper eval)+\n",
    "- Try a properly tuned model\n",
    "    - seems to get 92.47% acc, high variance (overfitting) on training data\n",
    "        - e_size=300, bs=128, lr=1e-3 got same acc in 6 epochs opposed to ~40\n",
    "    - might need a bigger batch size\n",
    "- Try learning rate finder\n",
    "- Learning rate cosine annealing\n",
    "- SGD with restarts\n",
    "- Try to predict multiple labels\n",
    "\n",
    "##### Analysis\n",
    "+ Can also check how balanced the classes are+\n",
    "    - Rework unbalanced classes or set class weights\n",
    "+ Try a simple shallow learning model+\n",
    "    - 94.5% accuracy, without fiddling with hyperparams and models much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:51:22.772369Z",
     "start_time": "2018-08-02T20:51:22.730846Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-5, random_state=42,\n",
    "                                           max_iter=25, tol=None)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.107962Z",
     "start_time": "2018-08-02T20:51:23.108451Z"
    }
   },
   "outputs": [],
   "source": [
    "text_clf.fit(train_texts, train_labels)  \n",
    "predicted = text_clf.predict(val_texts)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T20:55:00.115468Z",
     "start_time": "2018-08-02T20:55:00.109964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453833470733718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == np.asarray(val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "43px",
    "left": "1548px",
    "right": "20px",
    "top": "118px",
    "width": "302px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
